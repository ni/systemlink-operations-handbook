{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction \u00b6 The SystemLink Operations Handbook contains documentation, examples, and example config files for IT professionals to use when managing more advanced configurations of SystemLink Server . For information about how to install and use a SystemLink server, see the latest product manual on ni.com . Source and contributions for the handbook and example files can be found in the systemlink-operations-handbook GitHub repository . While the handbook is not specific to any version of SystemLink Server, the product continues to evolve over time. Some chapters or examples may specify a version or range of versions of SystemLink that they apply to.","title":"Introduction"},{"location":"#introduction","text":"The SystemLink Operations Handbook contains documentation, examples, and example config files for IT professionals to use when managing more advanced configurations of SystemLink Server . For information about how to install and use a SystemLink server, see the latest product manual on ni.com . Source and contributions for the handbook and example files can be found in the systemlink-operations-handbook GitHub repository . While the handbook is not specific to any version of SystemLink Server, the product continues to evolve over time. Some chapters or examples may specify a version or range of versions of SystemLink that they apply to.","title":"Introduction"},{"location":"data-stores/FileService-MinIO/","text":"Leverage File Service S3 for on-premises storage \u00b6 SystemLink File Service allows you to configure and use the Amazon S3 cloud storage instead of a file share. The File Service will also work with MinIO, a server-side software storage stack that is compatible with Amazon S3. You can configure and use an on-premises MinIO server. Due to limitations, however, connecting to GCS or Azure using the MinIO gateway is unsupported. To use MinIO with SystemLink, you need SystemLink version 2020 R3 or later. To use MinIO as a storage provider, set up the MinIO server on a system that you would like to upload files to. This can be the same machine as the SystemLink server or your own dedicated server. Then, configure the File Service to use that server. Running MinIO server \u00b6 Download the server application from the MinIO website . Since MinIO discourages use of the default credentials , you should change the access key and secret key. To do this, define the environment variables MINIO_ACCESS_KEY and MINIO_SECRET_KEY . Run the following command to start the server with individual access and secret keys: set MINIO_ACCESS_KEY = YourAccessKey set MINIO_SECRET_KEY = YourSecretKey minio server C : \\ minio Running a minio server. When starting the MinIO server for the first time, use a web browser and navigate to the URL that the command line prints out. Create a bucket by clicking the + button in the right bottom corner. Keep the command line open to keep the MinIO server running. For detailed information on how to run the server, follow the instructions from the MinIO Quickstart guide . Configuring File Service \u00b6 Follow the instructions from the documentation on uploading files to S3 to configure the File Service. a) Set the access key and secret key you chose when starting the MinIO server. b) Apply a valid bucket region. You can use any valid Amazon S3 region, like us-east-1 or eu-central-1 . c) Set the bucket name you created. Add two additional settings to the JSON configuration file at C:\\ProgramData\\National Instruments\\Skyline\\Config\\FileIngestion.json : S3BackEndServiceUrl : Set this value to ip:port of your MinIO server. You can obtain that from the MinIO output in your command line. S3ForcePathStyle : Set this value to True . You can paste the example code below into the config file and replace the placeholders with your actual values. \"UseS3BackEnd\" : \"True\" , \"S3BackEndBucketRegion\" : \"us-east-1\" , \"S3BackEndBucketName\" : \"<YourBucket>\" , \"S3BackEndAccessKeyId\" : \"<YourAccessKey>\" , \"S3BackEndSecretKey\" : \"<YourSecretKey>\" , \"S3BackEndFolderName\" : \"\" , \"S3BackEndServiceUrl\" : \"<YourServerIP>\" , \"S3ForcePathStyle\" : \"True\" In the NI SystemLink Server Configuration dialog, go to the NI SystemLink Service Manager tab and click Restart to apply the settings you made in the JSON file.","title":"Leverage File Service S3 for on-premises storage"},{"location":"data-stores/FileService-MinIO/#leverage-file-service-s3-for-on-premises-storage","text":"SystemLink File Service allows you to configure and use the Amazon S3 cloud storage instead of a file share. The File Service will also work with MinIO, a server-side software storage stack that is compatible with Amazon S3. You can configure and use an on-premises MinIO server. Due to limitations, however, connecting to GCS or Azure using the MinIO gateway is unsupported. To use MinIO with SystemLink, you need SystemLink version 2020 R3 or later. To use MinIO as a storage provider, set up the MinIO server on a system that you would like to upload files to. This can be the same machine as the SystemLink server or your own dedicated server. Then, configure the File Service to use that server.","title":"Leverage File Service S3 for on-premises storage"},{"location":"data-stores/FileService-MinIO/#running-minio-server","text":"Download the server application from the MinIO website . Since MinIO discourages use of the default credentials , you should change the access key and secret key. To do this, define the environment variables MINIO_ACCESS_KEY and MINIO_SECRET_KEY . Run the following command to start the server with individual access and secret keys: set MINIO_ACCESS_KEY = YourAccessKey set MINIO_SECRET_KEY = YourSecretKey minio server C : \\ minio Running a minio server. When starting the MinIO server for the first time, use a web browser and navigate to the URL that the command line prints out. Create a bucket by clicking the + button in the right bottom corner. Keep the command line open to keep the MinIO server running. For detailed information on how to run the server, follow the instructions from the MinIO Quickstart guide .","title":"Running MinIO server"},{"location":"data-stores/FileService-MinIO/#configuring-file-service","text":"Follow the instructions from the documentation on uploading files to S3 to configure the File Service. a) Set the access key and secret key you chose when starting the MinIO server. b) Apply a valid bucket region. You can use any valid Amazon S3 region, like us-east-1 or eu-central-1 . c) Set the bucket name you created. Add two additional settings to the JSON configuration file at C:\\ProgramData\\National Instruments\\Skyline\\Config\\FileIngestion.json : S3BackEndServiceUrl : Set this value to ip:port of your MinIO server. You can obtain that from the MinIO output in your command line. S3ForcePathStyle : Set this value to True . You can paste the example code below into the config file and replace the placeholders with your actual values. \"UseS3BackEnd\" : \"True\" , \"S3BackEndBucketRegion\" : \"us-east-1\" , \"S3BackEndBucketName\" : \"<YourBucket>\" , \"S3BackEndAccessKeyId\" : \"<YourAccessKey>\" , \"S3BackEndSecretKey\" : \"<YourSecretKey>\" , \"S3BackEndFolderName\" : \"\" , \"S3BackEndServiceUrl\" : \"<YourServerIP>\" , \"S3ForcePathStyle\" : \"True\" In the NI SystemLink Server Configuration dialog, go to the NI SystemLink Service Manager tab and click Restart to apply the settings you made in the JSON file.","title":"Configuring File Service"},{"location":"data-stores/mongodb/","text":"MongoDB \u00b6 The majority of SystemLink services use MongoDB as the primary database. Default installations of SystemLink include MongoDB Community Edition, which launches when the SystemLink server boots. This is referred to as a single node deployment. You can also host MongoDB on a separate standalone server, a replica set of three or more servers, or use MongoDB's platform as a service offering, MongoDB Atlas . This is referred to as a multi node deployment. Assumptions and Prerequisites \u00b6 Before you configure a remote MongoDB instance to use with SystemLink, ensure you have the following: A server running SystemLink 2021 R1 or greater. Refer to Installing and Configuring SystemLink Server and Clients for the basics of setting up a SystemLink server. A standalone server running MongoDB, multiple servers hosting a MongoDB replica set, or a MongoDB Atlas Account A user with the readWriteAnyDatabase role. The user must have the createCollection privilege and be able to create new databases. Refer to Role-Based Access Control for details. Important Due to a bug in a third-party MongoDB driver, SystemLink cannot connect to MongoDB instances where the MongoDB username contains either the - or the _ character. !!!important The readWrite role does not have the required createCollection privilege. Single Node vs Multi Node MongoDB Deployments \u00b6 The following table summarizes when to use the various supported configurations of MongoDB with SystemLink. Diagram SystemLink + MongoDB Configuration When to use Single node with defaults You have one server hosting both MongoDB and SystemLink. Use this during evaluation, when working with less than 10 managed nodes, and in deployments that don't need the Asset Manager and Test Insights modules. Single node with increased index cache You have one server hosting both MongoDB and SystemLink. Use this during evaluation, in moderate deployments of less than 25 managed nodes, and for moderate usage of the Test Insights module producing less than 100 test steps and results each day. Multi node with a single standalone MongoDB Instance You have SystemLink and MongoDB hosted on two separate servers. Use this configuration when the CPU, memory, and disk consumption of the MongoDB Windows service is impacting the operation of SystemLink services. While this configuration provides for greater reliability by splitting the servers running SystemLink and MongoDB, it does not provide greater redundancy for data storage. Multi node with MongoDB replica sets You have one dedicated server hosting SystemLink and three or more servers hosting MongoDB. NI recommends this configuration for all production deployments including small and moderately sized deployments. Use this to enable greater scale (>50 managed nodes, >1000 test steps and results daily). This configuration mitigates data loss with redundant replica sets. Refer to MongoDB documentation for setting up and hosting a MongoDB instance with replica sets. Multi node with MongoDB Atlas You have one dedicated server hosting SystemLink and are connecting to a MongoDB Atlas cluster. Use this configuration for large scale deployments (>200 managed nodes, 10,000 test steps and results daily) or to simplify database provisioning, operation, backup and restore. Refer to MongoDB Atlas for details on this service. Single Node Deployments \u00b6 By default, SystemLink stores all data on locally hosted databases and the local file system. For more reliable data storage and scalability, NI recommends remote data stores for all production deployments. Increasing the index cache size for single node deployments \u00b6 Increase the index cache size to process more data and use the Test Insights or Asset Management modules in a single-node deployment. This avoids high CPU usage that can occur with the default MongoDB memory constraint in SystemLink. NI recommends increasing the available memory for the index to 8GB. Refer to Sizing a SystemLink Server for system requirements to run SystemLink. Log into the desktop of the SystemLink server with administrator privileges. Open NI SystemLink Server Configuration . Navigate to NoSqlDatabase . Under The NoSqlServer is launched and managed by SystemLink , adjust the value in The cache size of the database in Gigabytes (GB) . Click Apply . SystemLink's NoSqlDatabase configuration set to 8GB Multi Node Deployments \u00b6 SystemLink supports three types of multi-node configuration. You can configure SystemLink to connect to a standalone instance, replica sets, or MongoDB Atlas. NI recommends connecting SystemLink to a replica set of three or more MongoDB members or MongoDB Atlas for all production deployments. NI does not support configurations where multiple SystemLink servers use the same MongoDB instance. NI does not support configurations where another application uses the same MongoDB instance as SystemLink. While SystemLink can connect to and use a sharded MongoDB cluster ( mongos ), it will not take advantage of horizontal scaling capabilities enabled by sharded clusters. When using MongoDB Atlas or MongoDB Enterprise Advanced , you can encrypt the data stored within the database. Connection String Formats The following connection string formats are unsupported or could cause issues in some environments: Connection strings that contain the query parameter tls= are unsupported. Use the ssl= query string to achieve the same degree of security. In environments where the 4.2.2.1 root DNS server cannot be reached, the DNS seed list URI format ( mongodb+srv:// ) will fail due to a bug ( Unable to connect to Atlas due to DNS connectivity issues #358 ) in a third-party MongoDB driver. In this case, use the MongoDB standard connection string format to connect your replica set. This affects both self-hosted replica sets and MongoDB Atlas. The mongodb+srv:// URI format provides for more flexible deployments because clients will not need a new connection string should the servers in the replica set change. When URL escaping characters in your connection string, you must use uppercase characters, e.g. %2F not %2f . Example connection string in the standard connection string format (line breaks for readability): mongodb://myusername:<password>@ ec2-123-123-12.compute-1.amazonaws.com27017, ec2-234-234-23.compute-1.amazonaws.com:27017, ec2-456-456-45.compute-1.amazonaws.com:27017/ ?authSource=admin &replicaSet=rs0 &readPreference=primary &ssl=true Consider using MongoDB Compass to connect to your replica set to help construct a valid connection string and verify the configuration. Connecting to Standalone MongoDB instance \u00b6 Using a separate server to host MongoDB increases reliability and lowers resource utilization for your SystemLink server. You may use the supplied form input in NI SystemLink Sever Configuration when connecting to a server hosting a single standalone MongoDB instance. Refer to Connecting to a Remote Mongo Database for more information. Connecting to MongoDB with Replica Sets \u00b6 Use replica sets to create redundancy in your database to mitigate against potential data loss. Refer to MongoDB for a tutorial on deploying replica sets . Note NI recommends x.509 certificates for replica set membership. To successfully connect to a MongoDB replica set and create redundancy, you must specify a connection string in NI SystemLink Server Configuration . Log into the desktop of the SystemLink server with administrator privileges. Open NI SystemLink Server Configuration . Navigate to NoSqlDatabase . Click the Connect to an externally managed NoSqlDatabase server radio button. Secure remote connections NI recommends securing communications between your SystemLink server and MongoDB instance with TLS. For details, refer to TLS for Remote MongoDB Instances . Select the Use a custom connection string checkbox. Enter your connection string. Refer to Connection String URI Format for details on structuring your connection string. Click Test Connection to ensure SystemLink can connect to the MongoDB instance. If the connection test was successful, click Apply to restart SystemLink service manager and connect to the MongoDB instance. Connecting to MongoDB Atlas \u00b6 MongoDB Atlas provides simpler setup and adminstration compared to self hosted replica sets and standalone deployments. MongoDB Atlas is a fully managed PaaS from MongoDB. If you have not setup an Atlas cluster before, refer to Getting started with Atlas . Refer to Setup Atlas Connectivity for steps to obtain a connection string. Note In the sample connection string provided by Atlas you will need to replace the instance of myFirstDatabase with admin . For example: mongodb+srv://<username>:<password>@<cluster>/myFirstDatabase?retryWrites=true&w=majority This will need to be updated to mongodb+srv://<username>:<password>@<cluster>/admin?retryWrites=true&w=majority MongoDB Atlas free tier is unsupported by SystemLink Due to memory constraints on the Atlas free tier, you must use a paid tier for SystemLink to successfully connect. SystemLink supports all paid tiers of Atlas. If you need assistance evaluating Atlas with SystemLink please contact NI ( customer.requests@ni.com ) or your local account manager. Because Atlas uses replica sets by default, your SystemLink server could be affected by the bug in the third-party MongoDB driver used by SystemLink as described in Multi Node Deployments . If you cannot use the mongodb+srv:// URI format, use the connection string generated for the Node.js driver version 2.0.14. This provided connection string is fully supported by SystemLink.","title":"MongoDB"},{"location":"data-stores/mongodb/#mongodb","text":"The majority of SystemLink services use MongoDB as the primary database. Default installations of SystemLink include MongoDB Community Edition, which launches when the SystemLink server boots. This is referred to as a single node deployment. You can also host MongoDB on a separate standalone server, a replica set of three or more servers, or use MongoDB's platform as a service offering, MongoDB Atlas . This is referred to as a multi node deployment.","title":"MongoDB"},{"location":"data-stores/mongodb/#assumptions-and-prerequisites","text":"Before you configure a remote MongoDB instance to use with SystemLink, ensure you have the following: A server running SystemLink 2021 R1 or greater. Refer to Installing and Configuring SystemLink Server and Clients for the basics of setting up a SystemLink server. A standalone server running MongoDB, multiple servers hosting a MongoDB replica set, or a MongoDB Atlas Account A user with the readWriteAnyDatabase role. The user must have the createCollection privilege and be able to create new databases. Refer to Role-Based Access Control for details. Important Due to a bug in a third-party MongoDB driver, SystemLink cannot connect to MongoDB instances where the MongoDB username contains either the - or the _ character. !!!important The readWrite role does not have the required createCollection privilege.","title":"Assumptions and Prerequisites"},{"location":"data-stores/mongodb/#single-node-vs-multi-node-mongodb-deployments","text":"The following table summarizes when to use the various supported configurations of MongoDB with SystemLink. Diagram SystemLink + MongoDB Configuration When to use Single node with defaults You have one server hosting both MongoDB and SystemLink. Use this during evaluation, when working with less than 10 managed nodes, and in deployments that don't need the Asset Manager and Test Insights modules. Single node with increased index cache You have one server hosting both MongoDB and SystemLink. Use this during evaluation, in moderate deployments of less than 25 managed nodes, and for moderate usage of the Test Insights module producing less than 100 test steps and results each day. Multi node with a single standalone MongoDB Instance You have SystemLink and MongoDB hosted on two separate servers. Use this configuration when the CPU, memory, and disk consumption of the MongoDB Windows service is impacting the operation of SystemLink services. While this configuration provides for greater reliability by splitting the servers running SystemLink and MongoDB, it does not provide greater redundancy for data storage. Multi node with MongoDB replica sets You have one dedicated server hosting SystemLink and three or more servers hosting MongoDB. NI recommends this configuration for all production deployments including small and moderately sized deployments. Use this to enable greater scale (>50 managed nodes, >1000 test steps and results daily). This configuration mitigates data loss with redundant replica sets. Refer to MongoDB documentation for setting up and hosting a MongoDB instance with replica sets. Multi node with MongoDB Atlas You have one dedicated server hosting SystemLink and are connecting to a MongoDB Atlas cluster. Use this configuration for large scale deployments (>200 managed nodes, 10,000 test steps and results daily) or to simplify database provisioning, operation, backup and restore. Refer to MongoDB Atlas for details on this service.","title":"Single Node vs Multi Node MongoDB Deployments"},{"location":"data-stores/mongodb/#single-node-deployments","text":"By default, SystemLink stores all data on locally hosted databases and the local file system. For more reliable data storage and scalability, NI recommends remote data stores for all production deployments.","title":"Single Node Deployments"},{"location":"data-stores/mongodb/#increasing-the-index-cache-size-for-single-node-deployments","text":"Increase the index cache size to process more data and use the Test Insights or Asset Management modules in a single-node deployment. This avoids high CPU usage that can occur with the default MongoDB memory constraint in SystemLink. NI recommends increasing the available memory for the index to 8GB. Refer to Sizing a SystemLink Server for system requirements to run SystemLink. Log into the desktop of the SystemLink server with administrator privileges. Open NI SystemLink Server Configuration . Navigate to NoSqlDatabase . Under The NoSqlServer is launched and managed by SystemLink , adjust the value in The cache size of the database in Gigabytes (GB) . Click Apply . SystemLink's NoSqlDatabase configuration set to 8GB","title":"Increasing the index cache size for single node deployments"},{"location":"data-stores/mongodb/#multi-node-deployments","text":"SystemLink supports three types of multi-node configuration. You can configure SystemLink to connect to a standalone instance, replica sets, or MongoDB Atlas. NI recommends connecting SystemLink to a replica set of three or more MongoDB members or MongoDB Atlas for all production deployments. NI does not support configurations where multiple SystemLink servers use the same MongoDB instance. NI does not support configurations where another application uses the same MongoDB instance as SystemLink. While SystemLink can connect to and use a sharded MongoDB cluster ( mongos ), it will not take advantage of horizontal scaling capabilities enabled by sharded clusters. When using MongoDB Atlas or MongoDB Enterprise Advanced , you can encrypt the data stored within the database. Connection String Formats The following connection string formats are unsupported or could cause issues in some environments: Connection strings that contain the query parameter tls= are unsupported. Use the ssl= query string to achieve the same degree of security. In environments where the 4.2.2.1 root DNS server cannot be reached, the DNS seed list URI format ( mongodb+srv:// ) will fail due to a bug ( Unable to connect to Atlas due to DNS connectivity issues #358 ) in a third-party MongoDB driver. In this case, use the MongoDB standard connection string format to connect your replica set. This affects both self-hosted replica sets and MongoDB Atlas. The mongodb+srv:// URI format provides for more flexible deployments because clients will not need a new connection string should the servers in the replica set change. When URL escaping characters in your connection string, you must use uppercase characters, e.g. %2F not %2f . Example connection string in the standard connection string format (line breaks for readability): mongodb://myusername:<password>@ ec2-123-123-12.compute-1.amazonaws.com27017, ec2-234-234-23.compute-1.amazonaws.com:27017, ec2-456-456-45.compute-1.amazonaws.com:27017/ ?authSource=admin &replicaSet=rs0 &readPreference=primary &ssl=true Consider using MongoDB Compass to connect to your replica set to help construct a valid connection string and verify the configuration.","title":"Multi Node Deployments"},{"location":"data-stores/mongodb/#connecting-to-standalone-mongodb-instance","text":"Using a separate server to host MongoDB increases reliability and lowers resource utilization for your SystemLink server. You may use the supplied form input in NI SystemLink Sever Configuration when connecting to a server hosting a single standalone MongoDB instance. Refer to Connecting to a Remote Mongo Database for more information.","title":"Connecting to Standalone MongoDB instance"},{"location":"data-stores/mongodb/#connecting-to-mongodb-with-replica-sets","text":"Use replica sets to create redundancy in your database to mitigate against potential data loss. Refer to MongoDB for a tutorial on deploying replica sets . Note NI recommends x.509 certificates for replica set membership. To successfully connect to a MongoDB replica set and create redundancy, you must specify a connection string in NI SystemLink Server Configuration . Log into the desktop of the SystemLink server with administrator privileges. Open NI SystemLink Server Configuration . Navigate to NoSqlDatabase . Click the Connect to an externally managed NoSqlDatabase server radio button. Secure remote connections NI recommends securing communications between your SystemLink server and MongoDB instance with TLS. For details, refer to TLS for Remote MongoDB Instances . Select the Use a custom connection string checkbox. Enter your connection string. Refer to Connection String URI Format for details on structuring your connection string. Click Test Connection to ensure SystemLink can connect to the MongoDB instance. If the connection test was successful, click Apply to restart SystemLink service manager and connect to the MongoDB instance.","title":"Connecting to MongoDB with Replica Sets"},{"location":"data-stores/mongodb/#connecting-to-mongodb-atlas","text":"MongoDB Atlas provides simpler setup and adminstration compared to self hosted replica sets and standalone deployments. MongoDB Atlas is a fully managed PaaS from MongoDB. If you have not setup an Atlas cluster before, refer to Getting started with Atlas . Refer to Setup Atlas Connectivity for steps to obtain a connection string. Note In the sample connection string provided by Atlas you will need to replace the instance of myFirstDatabase with admin . For example: mongodb+srv://<username>:<password>@<cluster>/myFirstDatabase?retryWrites=true&w=majority This will need to be updated to mongodb+srv://<username>:<password>@<cluster>/admin?retryWrites=true&w=majority MongoDB Atlas free tier is unsupported by SystemLink Due to memory constraints on the Atlas free tier, you must use a paid tier for SystemLink to successfully connect. SystemLink supports all paid tiers of Atlas. If you need assistance evaluating Atlas with SystemLink please contact NI ( customer.requests@ni.com ) or your local account manager. Because Atlas uses replica sets by default, your SystemLink server could be affected by the bug in the third-party MongoDB driver used by SystemLink as described in Multi Node Deployments . If you cannot use the mongodb+srv:// URI format, use the connection string generated for the Node.js driver version 2.0.14. This provided connection string is fully supported by SystemLink.","title":"Connecting to MongoDB Atlas"},{"location":"ldap/ldap/","text":"Sign on with LDAP \u00b6 You can configure SystemLink to use the Lightweight Directory Access Protocol (LDAP) for user authentication. Use LDAP attributes and groups to map users to roles and workspaces in SystemLink's role based access control system. Assumptions and Prerequisites \u00b6 A server running SystemLink. Refer to Installing and Configuring SystemLink Server and Clients for the basics of setting up a SystemLink server. Administrator desktop access to the SystemLink server. An LDAP server accessible to the SystemLink server. A bind user and bind password for the LDAP server. SystemLink supports anonymous connections. In this case the bind user and bind password are not needed. Familiarity with the LDAP attributes available to your organization. If you do not know what LDAP attributes and groups are available to you, talk with your LDAP system administrator. Tools such ADExplorer can be helpful to explore the attributes assigned to your users. Enabling LDAP in SystemLink \u00b6 Configuring Authentication \u00b6 Log into the server running SystemLink and open NI Web Sever Configuration . Go to the Authentication tab and enable Connect to an LDAP server . Enter the LDAP URL for your sever. Refer to LDAP URLs for details on how to structure this URL. Enter the bind user. Refer to Bind User for details on usernames that can be used here. Enter the bind password. Click Apply and Restart . Configuration needed to enable logging into a SystemLink server using LDAP credentials. You may now log in to the SystemLink server using your LDAP credentials. To access systems and data in SystemLink, configure workspace and role mappings. Refer to Mapping LDAP Attributes and Groups to SystemLink Workspaces and Roles for details. View from a user who can log in but does not have any workspace and role mappings. LDAP URL and Bind User \u00b6 You must provide a URL and bind user and bind password to establish an authenticated connection between your SystemLink server and LDAP server. LDAP URL \u00b6 The LDAP URL follows a standard scheme. URL Scheme <ldap>://<server-dns>:<port>/<target-entry-dn>?<username-attribute>?<scope>?<filter> protocol: ldap or ldaps for secure connections. SystemLink does not support STARTTLS, which allows connections over non-TLS and then initiates a TLS handshake. server-dns: The LDAP server SystemLink is connecting to. port: The port of the LDAP server. If your LDAP server is backed by Windows Active Directory, you may point to the global catalog on port 3268 to enable login from multiple domains (forest). target-entry-dn: The base search distinguished name (DN) for the LDAP directory. user-name-attribute: The attribute that determines the SystemLink username for login. scope: The scope of the directory search. Scope defaults to sub but can be set to one to restrict users to the base DN. filter: The LDAP search filter. This defaults to objectClass=* to find find all objects in the directory. This allows you to restrict login to users who have a specific attribute. Basic LDAP URL Example Example: ldap://example.com:389/dc=example,dc=com?sAMAccountName In this example the server is example.com , the port is 389, the base search DN is dc=example,dc=com and the LDAP attribute used for user login is sAMAccountName . Example LDAP URLs specifying different usernames for the user Jane Doe URL: ldap://example.com/dc=example,dc=com?sAMAccountName Username: jdoe URL: ldap://example.com/dc=example,dc=com?userPrincipalName Username: jane.doe@example.com Username jdoe is used because the sAMAccountName attribute is specified in the LDAP URL. If a username attribute is not specified NI Web Server Configuration will automatically add uid as the attribute. Depending on your LDAP directory setup this attribute may not be available. Bind User \u00b6 The bind user and bind password are used to authenticate with the LDAP server. Provide a distinguishedName or a userPrincipalName to specify the bind user. If the password for this user changes, NI Web Server Configuration must be updated for users to continue to log into SystemLink. Bind user formats for the user Jane Doe distinguishedName: cn=jdoe,dc=example,dc=com userPrincipalName: jane.doe@example.com Mapping LDAP Groups, Users, and Attributes to Workspaces and Roles \u00b6 To add a user or collection of users to a workspace and assign a role you must complete the role mapping workflow. Log in to the SystemLink web application with a user mapped to the Server Administrator role. Go to Access Control > Workspaces and click the gear icon in the top right. Create a new workspace or edit an existing workspace. Go to the Role Mappings tab. Click +MAPPING and select one of the available LDAP mapping types: LDAP Group , LDAP User , or LDAP Attribute . If you have have selected LDAP Attribute enter a valid key and value. For LDAP User or LDAP Group enter a valid value. LDAP Group Mapping \u00b6 LDAP Group mapping queries the objectClass of group (Active Directory specific), groupOfName , and groupOfUniqueNames to match either member or uniqueMember attributes of the group. !!! note Group names should be declared using the full LDAP distinguishedName of the group. cn=Users,dc=example,dc=com LDAP User Mapping \u00b6 You may specify a LDAP username when creating workspace and role mappings. The username you specify is the same as the usernames for logging into SystemLink. LDAP Attribute Mapping \u00b6 You can use any available LDAP attribute to create a workspace and role mapping. In this case both the name and value of the attribute must match exactly for the mapping to be successful. Example LDAP attribute mapping Mapping the country attribute c with the value US to the Data Maintainer Role in the Default workspace.","title":"Sign on with LDAP"},{"location":"ldap/ldap/#sign-on-with-ldap","text":"You can configure SystemLink to use the Lightweight Directory Access Protocol (LDAP) for user authentication. Use LDAP attributes and groups to map users to roles and workspaces in SystemLink's role based access control system.","title":"Sign on with LDAP"},{"location":"ldap/ldap/#assumptions-and-prerequisites","text":"A server running SystemLink. Refer to Installing and Configuring SystemLink Server and Clients for the basics of setting up a SystemLink server. Administrator desktop access to the SystemLink server. An LDAP server accessible to the SystemLink server. A bind user and bind password for the LDAP server. SystemLink supports anonymous connections. In this case the bind user and bind password are not needed. Familiarity with the LDAP attributes available to your organization. If you do not know what LDAP attributes and groups are available to you, talk with your LDAP system administrator. Tools such ADExplorer can be helpful to explore the attributes assigned to your users.","title":"Assumptions and Prerequisites"},{"location":"ldap/ldap/#enabling-ldap-in-systemlink","text":"","title":"Enabling LDAP in SystemLink"},{"location":"ldap/ldap/#configuring-authentication","text":"Log into the server running SystemLink and open NI Web Sever Configuration . Go to the Authentication tab and enable Connect to an LDAP server . Enter the LDAP URL for your sever. Refer to LDAP URLs for details on how to structure this URL. Enter the bind user. Refer to Bind User for details on usernames that can be used here. Enter the bind password. Click Apply and Restart . Configuration needed to enable logging into a SystemLink server using LDAP credentials. You may now log in to the SystemLink server using your LDAP credentials. To access systems and data in SystemLink, configure workspace and role mappings. Refer to Mapping LDAP Attributes and Groups to SystemLink Workspaces and Roles for details. View from a user who can log in but does not have any workspace and role mappings.","title":"Configuring Authentication"},{"location":"ldap/ldap/#ldap-url-and-bind-user","text":"You must provide a URL and bind user and bind password to establish an authenticated connection between your SystemLink server and LDAP server.","title":"LDAP URL and Bind User"},{"location":"ldap/ldap/#ldap-url","text":"The LDAP URL follows a standard scheme. URL Scheme <ldap>://<server-dns>:<port>/<target-entry-dn>?<username-attribute>?<scope>?<filter> protocol: ldap or ldaps for secure connections. SystemLink does not support STARTTLS, which allows connections over non-TLS and then initiates a TLS handshake. server-dns: The LDAP server SystemLink is connecting to. port: The port of the LDAP server. If your LDAP server is backed by Windows Active Directory, you may point to the global catalog on port 3268 to enable login from multiple domains (forest). target-entry-dn: The base search distinguished name (DN) for the LDAP directory. user-name-attribute: The attribute that determines the SystemLink username for login. scope: The scope of the directory search. Scope defaults to sub but can be set to one to restrict users to the base DN. filter: The LDAP search filter. This defaults to objectClass=* to find find all objects in the directory. This allows you to restrict login to users who have a specific attribute. Basic LDAP URL Example Example: ldap://example.com:389/dc=example,dc=com?sAMAccountName In this example the server is example.com , the port is 389, the base search DN is dc=example,dc=com and the LDAP attribute used for user login is sAMAccountName . Example LDAP URLs specifying different usernames for the user Jane Doe URL: ldap://example.com/dc=example,dc=com?sAMAccountName Username: jdoe URL: ldap://example.com/dc=example,dc=com?userPrincipalName Username: jane.doe@example.com Username jdoe is used because the sAMAccountName attribute is specified in the LDAP URL. If a username attribute is not specified NI Web Server Configuration will automatically add uid as the attribute. Depending on your LDAP directory setup this attribute may not be available.","title":"LDAP URL"},{"location":"ldap/ldap/#bind-user","text":"The bind user and bind password are used to authenticate with the LDAP server. Provide a distinguishedName or a userPrincipalName to specify the bind user. If the password for this user changes, NI Web Server Configuration must be updated for users to continue to log into SystemLink. Bind user formats for the user Jane Doe distinguishedName: cn=jdoe,dc=example,dc=com userPrincipalName: jane.doe@example.com","title":"Bind User"},{"location":"ldap/ldap/#mapping-ldap-groups-users-and-attributes-to-workspaces-and-roles","text":"To add a user or collection of users to a workspace and assign a role you must complete the role mapping workflow. Log in to the SystemLink web application with a user mapped to the Server Administrator role. Go to Access Control > Workspaces and click the gear icon in the top right. Create a new workspace or edit an existing workspace. Go to the Role Mappings tab. Click +MAPPING and select one of the available LDAP mapping types: LDAP Group , LDAP User , or LDAP Attribute . If you have have selected LDAP Attribute enter a valid key and value. For LDAP User or LDAP Group enter a valid value.","title":"Mapping LDAP Groups, Users, and Attributes to Workspaces and Roles"},{"location":"ldap/ldap/#ldap-group-mapping","text":"LDAP Group mapping queries the objectClass of group (Active Directory specific), groupOfName , and groupOfUniqueNames to match either member or uniqueMember attributes of the group. !!! note Group names should be declared using the full LDAP distinguishedName of the group. cn=Users,dc=example,dc=com","title":"LDAP Group Mapping"},{"location":"ldap/ldap/#ldap-user-mapping","text":"You may specify a LDAP username when creating workspace and role mappings. The username you specify is the same as the usernames for logging into SystemLink.","title":"LDAP User Mapping"},{"location":"ldap/ldap/#ldap-attribute-mapping","text":"You can use any available LDAP attribute to create a workspace and role mapping. In this case both the name and value of the attribute must match exactly for the mapping to be successful. Example LDAP attribute mapping Mapping the country attribute c with the value US to the Data Maintainer Role in the Default workspace.","title":"LDAP Attribute Mapping"},{"location":"network-security/network-security/","text":"Network Security \u00b6 SystemLink connects test systems to a central server to aggregate data for monitoring and analysis. SystemLink uses industry standard tools and best practices to ensure the SystemLink server and test systems utilize secure networking techniques. Refer to Workspaces and Role-based Access Control for details secure user interactions with SystemLink resources. Refer to Single Sign-on with OpenID Connect and Sign on with LDAP for details on securely authenticating with SystemLink. Summary of SystemLink Network Security Best Practices \u00b6 Use firewalls to restrict open ports to only those needed by your environment. Do not expose Salt ports on the SystemLink server to the public internet. Configure NI Web Server to use HTTPS. Disable Cross Origin Resource Sharing. Use LDAPS for communication between your SystemLink server and LDAP server. Use HTTPS for communication between your SystemLink server and OpenID Connect provider. If using a remotely connected MongoDB instances, configure this instance to use TLS communication. Disable AMQP for client access. Use a network load balancer to mitigate against Denial of Service (DoS) threats. Network diagram \u00b6 The networked components and encrypted protocols used by SystemLink. Note Refer to Setting up a SystemLink Server for information regarding ports used by SystemLink. Although AMQP is enabled by default it is not shown. Refer to Deprecation of AMQP for details . SystemLink Application Server : This Windows server hosts NI Web Server, the various SystemLink web services, SystemLink web applications, and a Salt master. In the single-box setup, MongoDB and SystemLink file service storage are hosted on the application server. Refer to Sizing a SystemLink Server for details on server system requirements. Securing desktop access to the application server is outside the scope of this document. Configure server access according to the IT policies of your site. SystemLink Web Application The SystemLink web application is the primary way users interact with SystemLink. NI recommends HTTPS for all production environments. Refer to NI Web Server for details on configuring encrypted communication. Targets Targets are Windows and Linux RT systems whose software and configuration are managed by SystemLink. Software configuration occurs via the SaltStack Transport Protocol . Refer to Target to SystemLink Communication for details regarding how SystemLink encrypts this communication. File, tag, test, and asset data are published to the SystemLink application server over HTTPS. MongoDB MongoDB is the primary database used by SystemLink's web services. The MongoDB wire protocol is used to communicate with the MongoDB instance. Refer to TLS for Remote MongoDB Instances for details on enabling TLS communication. File Service Storage The SystemLink file service can be configured to store files on either Network Attached Storage (NAS) or AWS S3. NAS uses the SMB protocol. The SMB protocol can be configured to use AES encryption. Refer to SMB security enhancements for details and steps to secure this transport. AWS S3 uses HTTPS. Refer to the SystemLink manual for steps to enable S3 file storage. DataFinder (not shown) DataFinder enables indexing and searching for files stored on network drives. DataFinder's network communication cannot be secured with TLS. Identity Provider Active Directory, LDAP, and OpenID Connect are supported identity providers. Local Windows accounts may also be used (not shown). Active Directory uses the Active Directory protocol. LDAP uses the ldap or the ldaps protocols. Refer to Sign-on with LDAP . and Single Sign-on with OpenID Connect for details on setting up these identity providers. NI VLM NI Volume License Manager (VLM) is used to enforce SystemLink node licenses. NI VLM uses TCP and does not support encrypted communication. Refer to Licensing SystemLink Products for details on using VLM with SystemLink. NI Web Server \u00b6 NI Web Server is based on Apache httpd and includes the NI Web Server Configuration utility to guide the selection of secure presets as well as a GUI for setting underlying Apache httpd configurations. Note NI Web Server ships with SystemLink and various other NI software products such as LabVIEW. Refer to the NI Web Server manual for step by step instructions to configure your web server. HTTPS in NI Web Server \u00b6 NI Web Server supports TLS 1.3. NI Web Server Configuration supports creating self-signed certificates, certificate signing requests (CSR), and installing certificates generated by a certificate authority. The DNS settings for the server can affect the operability of these certificates. Refer to DNS Configuration for details. NI recommends including the fully qualified domain (FQDN) name for your SystemLink Server in either the common name or subject alternative name of your certificate. Warn Self-signed certificates should be used for testing purposes only. Limited capabilities when using self-signed certificates Clients will not trust self-signed certificates by default. This can prevent some operations from occurring. Web browsers will not trust the certificate and the user must grant an exception to load the SystemLink web application. Packages built in LabVIEW cannot be automatically published to the SystemLink server. The LabVIEW Client API must explicitly disable verify server checks to communicate with the server. Refer to Open Configuration for details on this setting. When you have received a certificate from an certificate signing authority, you can use NI Web Server Configuration to install the certificate. Open NI Web Sever Configuration and navigate to the HTTPS tab. Click the Use a certificate from a signing authority radio button. Expand the Install an already signed certificate section. Click the folder icon next to Certificate file and browse to your certificate file. Click the folder icon next to Key file and select your key file. Click the Enable HTTP Strict Transport Security checkbox to include the Strict-Transport-Security header in all responses sent by this server. This is strongly recommended but not required. If needed change the HTTPS port from the default, 443. Click Apply and restart . TLS certificates with application load balancers If you have a load balancer in front of your SystemLink application server you must ensure the same certificate is installed on both the load balancer and NI Web Server for targets to successfully connect and publish data to SystemLink. Specifying custom Diffie-Helman parameters \u00b6 The TLS protocol typically uses the Diffie-Hellman key exchange algorithm as part of its connection handshake. The Diffie-Hellman algorithm requires the server to provide a prime number as an input to the algorithm. By default, NI Web Server uses a set of default prime values defined by the Apache Web Server for this purpose. This approach is sufficient for many use cases, but, when additional security is required, a custom value can be provided in place of the defaults. These instructions use the copy of OpenSSL installed with SystemLink 23.5 or later. A different copy of OpenSSL can be substituted if desired. Open a command prompt on the SystemLink Server machine. Run \"c:\\Program Files\\National Instruments\\Shared\\Skyline\\OpenSSL\\openssl.exe dhparam -outform PEM -out dhparam.txt <numbits> The <numbits> value specifies a bit length for the prime. The bit length must be one of 1024, 2048, 3072, 4096, 7680, or 8192 bits. A length of at least 3072 bits is strongly recommended . OpenSSL will run for some time and produce a file called dhparam.txt in the current directory. Open this file in Notepad or another preferred text editor. Run Notepad as an administrator. Open the NI Web Server certificate. This file is located at C:\\Program Files\\National Instruments\\Shared\\Web Server\\certs\\ . The actual name of the certificate file will vary per deployment. If there are multiple certificate files in this directory, open C:\\Program Files\\National Instruments\\Shared\\Web Server\\conf\\defines.d\\50_httpd-defines.conf and use the file specified by the TLS_CERTIFICATE_PATH variable. Copy the entire contents of dhparam.txt. Scroll to the end of the certificate file. Paste the dhparam contents on the line after the final -----END CERTIFICATE----- line. Save and close the certificate file. Open NI Web Sever Configuration and navigate to the Control tab. Click the Restart button and wait for the server to restart. Note Longer parameters will increase the computational cost of handling each TLS connection to the server. Additionally, older TLS client applications may not support longer keys. Testing should be performed prior to deployment to production. Warn This process must be repeated any time you update the configured HTTP certificate in the NI Web Sever Configuration tool. DNS Configuration \u00b6 SystemLink and NI Web Server do not ship with a DNS server. NI assumes you will provide a DNS server for your environment. NI Web Server will provide a default for the DNS of your SystemLink server based on Windows OS settings. Other valid DNS names are listed in the Preferred host name for generated URLs and certificates combo box. You may also manually add hostnames as needed. As the name of the combo box implies, this setting must match the host name in your TLS certificates. If you are using OpenID Connect this DNS must also be used in your OpenID Connect redirect URI configuration . If an invalid hostname is provided data from managed targets will not be received by SystemLink. Cross Origin Resource Sharing and Remote Connections \u00b6 NI recommends disabling Cross Origin Resource Sharing (CORS) in production environments. In practice, CORS may need to be enabled to facilitate workflows for users developing web applications that interact with SystemLink's API. For this scenario, NI recommends setting up a test SystemLink server with CORS enabled. NI Web Server Configuration exposes settings for choosing a remote connection and automatically sets Windows Firewall rules. This ensures connections may only be established by clients on your preferred network. Refer to Choosing Remote Settings for details on the various CORS and remote connection settings. Target to SystemLink communication \u00b6 Test Systems communicate with SystemLink over HTTP(S) and the SaltStack TCP protocol. Regardless of protocol, All communication is initiated by the test system to the server. Refer to the SystemLink manual for prerequisites and steps to add a Linux RT or Windows target to your SystemLink server. Data published over HTTPS includes tags, files, assets, and test results. Salt jobs and pillars communicate over the AES encrypted Salt TCP transport. Salt jobs are used for installing software and changing target configuration from SystemLink server. Salt pillars are used to transfer credentials and certificates. The certificates used on the SystemLink server and target nodes are managed by Salt and do not require administrators to explicitly manage these certificates. Refer to SaltStack's documentation for an overview of the Salt TCP Transport. Managed NI LinuxRT Nodes NI recommends assigning a strong password for the admin user on the target. These credentials are required to SSH into the target. These credentials are also required when a SystemLink server adds a Linux RT target to its collection of managed systems. When a target is approved by SystemLink and becomes a managed node, SystemLink securely transfers configuration, certificates, and credentials needed to authenticate with the SystemLink server's role-based access control system . SystemLink client APIs include an Auto configuration VI that automatically consumes these credentials. This prevents the need to include credentials and other secrets in your test application code. Do not expose Salt ports to the public internet Due to the capabilities of Salt, users should configure firewalls and appropriate CIDR blocks to prevent exposing Salt ports (4505 and 4506) to the public internet. TLS for remote MongoDB Instances \u00b6 MongoDB support TLS connections. Refer to the MongoDB manual for details on enabling TLS. NI recommends enabling TLS for remote MongoDB connections. Note SystemLink does not support mongod instances configured with client certificate validation . Ensure your mongod is started without this requirement to allow SystemLink to successfully connect. Connecting to MongoDB Using Self-signed certificates \u00b6 Warn Self-signed certificates should be used for testing purposes only. Refer to the MongoDB manual for steps to create and run mongod with a self-signed certificate. The following refers to certificate names created by following MongoDB's documentation. Running MongoDB without Client certificate validation Option 1: Start mongod with command line arguments mongod --tlsMode requireTLS --tlscertificateKeyFile /etc/ssl/test-server1.pem --port 27017 --dbpath /var/lib/mongo --bind_ip_all Option 2: Start mongod with a Mongo Configuration file net : port : 27017 bindIp : 0.0.0.0 tls : mode : requireTLS certificateKeyFile : /etc/ssl/test-server1.pem systemLog : destination : file logAppend : true path : /var/log/mongodb/mongod.log storage : dbPath : /var/lib/mongo journal : enabled : true processManagement : fork : true # fork and run in background pidFilePath : /var/run/mongodb/mongod.pid # location of pidfile timeZoneInfo : /usr/share/zoneinfo Installing MongoDB Self-Signed certificates \u00b6 If you are using a self-signed certificate on your mongod instance you must install the certificate authority (CA) certificate and intermediary certificate into the SystemLink application server. Copy the CA and intermediary .crt files to your SystemLink application server. Double click on the CA certificate and click Install certificate... . Note If you are following the MongoDB manual appendix this file is named mongodb-test-ca.crt . In the Store Location field select the Local Machine radio button and click Next . Select the Place all certificate in the following store radio button. Click Browse , select Trusted Root Certificate Authorities and click OK . Click Next , review the settings, and click Finish to install the certificate. Double click on the intermediary certificate and click Install certificate... . Note If you are following the MongoDB manual appendix this file is named mongodb-test-ia.crt . In the Store Location field select the Local Machine radio button and click Next . Select the Place all certificates in the following store radio button. Click Browse , select Intermediate certificate Authorities and click OK . Click Next , review the settings, and click Finish to install the certificate. Note Ensure Use Transport Layer Security (TLS) encryption is enabled in the NoSqlDatabase section of the SystemLink Server Configuration application. Deprecation of AMQP \u00b6 AMQP as a transport protocol for target-to-server communication is deprecated in favor for HTTP(S). NI recommends disabling AMQP on the server and updating test applications to use the HTTP version of SystemLink APIs. Open NI SystemLink Server Configuration . Go to Security . Uncheck Enable AMQP client access (less secure) .","title":"Network Security"},{"location":"network-security/network-security/#network-security","text":"SystemLink connects test systems to a central server to aggregate data for monitoring and analysis. SystemLink uses industry standard tools and best practices to ensure the SystemLink server and test systems utilize secure networking techniques. Refer to Workspaces and Role-based Access Control for details secure user interactions with SystemLink resources. Refer to Single Sign-on with OpenID Connect and Sign on with LDAP for details on securely authenticating with SystemLink.","title":"Network Security"},{"location":"network-security/network-security/#summary-of-systemlink-network-security-best-practices","text":"Use firewalls to restrict open ports to only those needed by your environment. Do not expose Salt ports on the SystemLink server to the public internet. Configure NI Web Server to use HTTPS. Disable Cross Origin Resource Sharing. Use LDAPS for communication between your SystemLink server and LDAP server. Use HTTPS for communication between your SystemLink server and OpenID Connect provider. If using a remotely connected MongoDB instances, configure this instance to use TLS communication. Disable AMQP for client access. Use a network load balancer to mitigate against Denial of Service (DoS) threats.","title":"Summary of SystemLink Network Security Best Practices"},{"location":"network-security/network-security/#network-diagram","text":"The networked components and encrypted protocols used by SystemLink. Note Refer to Setting up a SystemLink Server for information regarding ports used by SystemLink. Although AMQP is enabled by default it is not shown. Refer to Deprecation of AMQP for details . SystemLink Application Server : This Windows server hosts NI Web Server, the various SystemLink web services, SystemLink web applications, and a Salt master. In the single-box setup, MongoDB and SystemLink file service storage are hosted on the application server. Refer to Sizing a SystemLink Server for details on server system requirements. Securing desktop access to the application server is outside the scope of this document. Configure server access according to the IT policies of your site. SystemLink Web Application The SystemLink web application is the primary way users interact with SystemLink. NI recommends HTTPS for all production environments. Refer to NI Web Server for details on configuring encrypted communication. Targets Targets are Windows and Linux RT systems whose software and configuration are managed by SystemLink. Software configuration occurs via the SaltStack Transport Protocol . Refer to Target to SystemLink Communication for details regarding how SystemLink encrypts this communication. File, tag, test, and asset data are published to the SystemLink application server over HTTPS. MongoDB MongoDB is the primary database used by SystemLink's web services. The MongoDB wire protocol is used to communicate with the MongoDB instance. Refer to TLS for Remote MongoDB Instances for details on enabling TLS communication. File Service Storage The SystemLink file service can be configured to store files on either Network Attached Storage (NAS) or AWS S3. NAS uses the SMB protocol. The SMB protocol can be configured to use AES encryption. Refer to SMB security enhancements for details and steps to secure this transport. AWS S3 uses HTTPS. Refer to the SystemLink manual for steps to enable S3 file storage. DataFinder (not shown) DataFinder enables indexing and searching for files stored on network drives. DataFinder's network communication cannot be secured with TLS. Identity Provider Active Directory, LDAP, and OpenID Connect are supported identity providers. Local Windows accounts may also be used (not shown). Active Directory uses the Active Directory protocol. LDAP uses the ldap or the ldaps protocols. Refer to Sign-on with LDAP . and Single Sign-on with OpenID Connect for details on setting up these identity providers. NI VLM NI Volume License Manager (VLM) is used to enforce SystemLink node licenses. NI VLM uses TCP and does not support encrypted communication. Refer to Licensing SystemLink Products for details on using VLM with SystemLink.","title":"Network diagram"},{"location":"network-security/network-security/#ni-web-server","text":"NI Web Server is based on Apache httpd and includes the NI Web Server Configuration utility to guide the selection of secure presets as well as a GUI for setting underlying Apache httpd configurations. Note NI Web Server ships with SystemLink and various other NI software products such as LabVIEW. Refer to the NI Web Server manual for step by step instructions to configure your web server.","title":"NI Web Server"},{"location":"network-security/network-security/#https-in-ni-web-server","text":"NI Web Server supports TLS 1.3. NI Web Server Configuration supports creating self-signed certificates, certificate signing requests (CSR), and installing certificates generated by a certificate authority. The DNS settings for the server can affect the operability of these certificates. Refer to DNS Configuration for details. NI recommends including the fully qualified domain (FQDN) name for your SystemLink Server in either the common name or subject alternative name of your certificate. Warn Self-signed certificates should be used for testing purposes only. Limited capabilities when using self-signed certificates Clients will not trust self-signed certificates by default. This can prevent some operations from occurring. Web browsers will not trust the certificate and the user must grant an exception to load the SystemLink web application. Packages built in LabVIEW cannot be automatically published to the SystemLink server. The LabVIEW Client API must explicitly disable verify server checks to communicate with the server. Refer to Open Configuration for details on this setting. When you have received a certificate from an certificate signing authority, you can use NI Web Server Configuration to install the certificate. Open NI Web Sever Configuration and navigate to the HTTPS tab. Click the Use a certificate from a signing authority radio button. Expand the Install an already signed certificate section. Click the folder icon next to Certificate file and browse to your certificate file. Click the folder icon next to Key file and select your key file. Click the Enable HTTP Strict Transport Security checkbox to include the Strict-Transport-Security header in all responses sent by this server. This is strongly recommended but not required. If needed change the HTTPS port from the default, 443. Click Apply and restart . TLS certificates with application load balancers If you have a load balancer in front of your SystemLink application server you must ensure the same certificate is installed on both the load balancer and NI Web Server for targets to successfully connect and publish data to SystemLink.","title":"HTTPS in NI Web Server"},{"location":"network-security/network-security/#specifying-custom-diffie-helman-parameters","text":"The TLS protocol typically uses the Diffie-Hellman key exchange algorithm as part of its connection handshake. The Diffie-Hellman algorithm requires the server to provide a prime number as an input to the algorithm. By default, NI Web Server uses a set of default prime values defined by the Apache Web Server for this purpose. This approach is sufficient for many use cases, but, when additional security is required, a custom value can be provided in place of the defaults. These instructions use the copy of OpenSSL installed with SystemLink 23.5 or later. A different copy of OpenSSL can be substituted if desired. Open a command prompt on the SystemLink Server machine. Run \"c:\\Program Files\\National Instruments\\Shared\\Skyline\\OpenSSL\\openssl.exe dhparam -outform PEM -out dhparam.txt <numbits> The <numbits> value specifies a bit length for the prime. The bit length must be one of 1024, 2048, 3072, 4096, 7680, or 8192 bits. A length of at least 3072 bits is strongly recommended . OpenSSL will run for some time and produce a file called dhparam.txt in the current directory. Open this file in Notepad or another preferred text editor. Run Notepad as an administrator. Open the NI Web Server certificate. This file is located at C:\\Program Files\\National Instruments\\Shared\\Web Server\\certs\\ . The actual name of the certificate file will vary per deployment. If there are multiple certificate files in this directory, open C:\\Program Files\\National Instruments\\Shared\\Web Server\\conf\\defines.d\\50_httpd-defines.conf and use the file specified by the TLS_CERTIFICATE_PATH variable. Copy the entire contents of dhparam.txt. Scroll to the end of the certificate file. Paste the dhparam contents on the line after the final -----END CERTIFICATE----- line. Save and close the certificate file. Open NI Web Sever Configuration and navigate to the Control tab. Click the Restart button and wait for the server to restart. Note Longer parameters will increase the computational cost of handling each TLS connection to the server. Additionally, older TLS client applications may not support longer keys. Testing should be performed prior to deployment to production. Warn This process must be repeated any time you update the configured HTTP certificate in the NI Web Sever Configuration tool.","title":"Specifying custom Diffie-Helman parameters"},{"location":"network-security/network-security/#dns-configuration","text":"SystemLink and NI Web Server do not ship with a DNS server. NI assumes you will provide a DNS server for your environment. NI Web Server will provide a default for the DNS of your SystemLink server based on Windows OS settings. Other valid DNS names are listed in the Preferred host name for generated URLs and certificates combo box. You may also manually add hostnames as needed. As the name of the combo box implies, this setting must match the host name in your TLS certificates. If you are using OpenID Connect this DNS must also be used in your OpenID Connect redirect URI configuration . If an invalid hostname is provided data from managed targets will not be received by SystemLink.","title":"DNS Configuration"},{"location":"network-security/network-security/#cross-origin-resource-sharing-and-remote-connections","text":"NI recommends disabling Cross Origin Resource Sharing (CORS) in production environments. In practice, CORS may need to be enabled to facilitate workflows for users developing web applications that interact with SystemLink's API. For this scenario, NI recommends setting up a test SystemLink server with CORS enabled. NI Web Server Configuration exposes settings for choosing a remote connection and automatically sets Windows Firewall rules. This ensures connections may only be established by clients on your preferred network. Refer to Choosing Remote Settings for details on the various CORS and remote connection settings.","title":"Cross Origin Resource Sharing and Remote Connections"},{"location":"network-security/network-security/#target-to-systemlink-communication","text":"Test Systems communicate with SystemLink over HTTP(S) and the SaltStack TCP protocol. Regardless of protocol, All communication is initiated by the test system to the server. Refer to the SystemLink manual for prerequisites and steps to add a Linux RT or Windows target to your SystemLink server. Data published over HTTPS includes tags, files, assets, and test results. Salt jobs and pillars communicate over the AES encrypted Salt TCP transport. Salt jobs are used for installing software and changing target configuration from SystemLink server. Salt pillars are used to transfer credentials and certificates. The certificates used on the SystemLink server and target nodes are managed by Salt and do not require administrators to explicitly manage these certificates. Refer to SaltStack's documentation for an overview of the Salt TCP Transport. Managed NI LinuxRT Nodes NI recommends assigning a strong password for the admin user on the target. These credentials are required to SSH into the target. These credentials are also required when a SystemLink server adds a Linux RT target to its collection of managed systems. When a target is approved by SystemLink and becomes a managed node, SystemLink securely transfers configuration, certificates, and credentials needed to authenticate with the SystemLink server's role-based access control system . SystemLink client APIs include an Auto configuration VI that automatically consumes these credentials. This prevents the need to include credentials and other secrets in your test application code. Do not expose Salt ports to the public internet Due to the capabilities of Salt, users should configure firewalls and appropriate CIDR blocks to prevent exposing Salt ports (4505 and 4506) to the public internet.","title":"Target to SystemLink communication"},{"location":"network-security/network-security/#tls-for-remote-mongodb-instances","text":"MongoDB support TLS connections. Refer to the MongoDB manual for details on enabling TLS. NI recommends enabling TLS for remote MongoDB connections. Note SystemLink does not support mongod instances configured with client certificate validation . Ensure your mongod is started without this requirement to allow SystemLink to successfully connect.","title":"TLS for remote MongoDB Instances"},{"location":"network-security/network-security/#connecting-to-mongodb-using-self-signed-certificates","text":"Warn Self-signed certificates should be used for testing purposes only. Refer to the MongoDB manual for steps to create and run mongod with a self-signed certificate. The following refers to certificate names created by following MongoDB's documentation. Running MongoDB without Client certificate validation Option 1: Start mongod with command line arguments mongod --tlsMode requireTLS --tlscertificateKeyFile /etc/ssl/test-server1.pem --port 27017 --dbpath /var/lib/mongo --bind_ip_all Option 2: Start mongod with a Mongo Configuration file net : port : 27017 bindIp : 0.0.0.0 tls : mode : requireTLS certificateKeyFile : /etc/ssl/test-server1.pem systemLog : destination : file logAppend : true path : /var/log/mongodb/mongod.log storage : dbPath : /var/lib/mongo journal : enabled : true processManagement : fork : true # fork and run in background pidFilePath : /var/run/mongodb/mongod.pid # location of pidfile timeZoneInfo : /usr/share/zoneinfo","title":"Connecting to MongoDB Using Self-signed certificates"},{"location":"network-security/network-security/#installing-mongodb-self-signed-certificates","text":"If you are using a self-signed certificate on your mongod instance you must install the certificate authority (CA) certificate and intermediary certificate into the SystemLink application server. Copy the CA and intermediary .crt files to your SystemLink application server. Double click on the CA certificate and click Install certificate... . Note If you are following the MongoDB manual appendix this file is named mongodb-test-ca.crt . In the Store Location field select the Local Machine radio button and click Next . Select the Place all certificate in the following store radio button. Click Browse , select Trusted Root Certificate Authorities and click OK . Click Next , review the settings, and click Finish to install the certificate. Double click on the intermediary certificate and click Install certificate... . Note If you are following the MongoDB manual appendix this file is named mongodb-test-ia.crt . In the Store Location field select the Local Machine radio button and click Next . Select the Place all certificates in the following store radio button. Click Browse , select Intermediate certificate Authorities and click OK . Click Next , review the settings, and click Finish to install the certificate. Note Ensure Use Transport Layer Security (TLS) encryption is enabled in the NoSqlDatabase section of the SystemLink Server Configuration application.","title":"Installing MongoDB Self-Signed certificates"},{"location":"network-security/network-security/#deprecation-of-amqp","text":"AMQP as a transport protocol for target-to-server communication is deprecated in favor for HTTP(S). NI recommends disabling AMQP on the server and updating test applications to use the HTTP version of SystemLink APIs. Open NI SystemLink Server Configuration . Go to Security . Uncheck Enable AMQP client access (less secure) .","title":"Deprecation of AMQP"},{"location":"openid-connect/openid-connect/","text":"Single Sign-on with OpenID Connect \u00b6 You can configure SystemLink to use OpenID Connect to authorize users. This enables SystemLink to use a common identity for users across multiple applications. This also means SystemLink leverages corporate single sign-on (SSO) and all its security benefits, such as streamlined login and limiting user credential proliferation. You can use OpenID Connect alongside or as a replacement for LDAP, Active Directory, and local Windows accounts for authentication. Assumptions and Prerequisites \u00b6 A server running SystemLink 2020R4 or greater. Refer to Installing and Configuring SystemLink Server and Clients for the basics of setting up a SystemLink server An active Advanced Server license for the SystemLink server. If the license is inactive or expires, users will be able to log in with OpenID Connect, but they will not have any permissions and will see a blank page. A DNS name for the SystemLink server SystemLink login with the Server Administrator role Administrator desktop access to the SystemLink server An OpenID Connect Provider server such as PingFederate , Azure ADFS , Okta , or another certified provider that has been fully set up and configured for OpenID Connect authentication Enabling OpenID Connect in SystemLink \u00b6 Log into the server running SystemLink and go to C:\\Program Files\\National Instruments\\Shared\\Web Server\\conf\\openidc . Add the configuration files to SystemLink to connect to your OpenID Connect provider. For details, refer to OpenID Connect Configuration Files in SystemLink Server . In SystemLink 2021R1 and later, configure the claim to use as the SystemLink username. This step is optional, but should be done before users begin using the server. For details, refer to Configuring the SystemLink Username . Open NI Web Server Configuration . Go to the Authentication tab and enable Use OpenID Connect (advanced) . Click Apply and restart . Log into the SystemLink web application with a user assigned the Server Administrator role. Go to Access Control > Roles and click the gear icon in the top right. Add an OpenID Connect Claim mapping for the Server Administrator role. For details, refer to Mapping OpenID Connect Claims to SystemLink Workspaces and Roles . Log out and log in as an OpenID Connect user with a mapping for the Server Administrator role and confirm they have the correct privileges. Enable OpenID Connect in NI Web Server OpenID Connect Configuration Files in SystemLink Server \u00b6 There are three files that you must create to connect your SystemLink server to an OpenID Connect provider: [provider-issuer-uri].conf , [provider-issuer-uri].client , and [provider-issuer-uri].provider . The [provider-issuer-uri] portion of each filename must be the URL-encoded fully qualified domain name. Refer to openid-connect-config for examples of each of these files. Example An OpenID Connect provider with the issuer URI example.com:9999/v2 would yield files named example.com%3A9999%2Fv2.conf , example.com%3A9999%2Fv2.client , and example.com%3A9999%2Fv2.provider . You can find the issuer URI by viewing the issuer property at your provider's OpenID Connect configuration endpoint. For example https://example.com:9999/v2/.well-known/openid-configuration . These files do not exist for new SystemLink installations. Add each file to C:\\Program Files\\National Instruments\\Shared\\Web Server\\conf\\openidc . Restart the NI Web Server to apply changes. You can configure SystemLink to support multiple OpenID Connect providers simultaneously by creating a [provider-issuer-uri].conf , [provider-issuer-uri.client , and [provider-issuer-uri].provider file for each provider. The user ID in SystemLink must be unique across providers. This ID takes the form [sub_claim]@issuer . You can see the ID SystemLink associates with a user in the user details in SystemLink Access Control. SystemLink Login Configuration \u00b6 [provider-issuer-uri].conf describes the scopes SystemLink will request, the text and icon for the provider login button, and private keys for ID token key management encryption. { \"scope\" : \"openid email profile\" , \"ni-attributes\" : { \"displayName\" : \"Log in with PingFederate\" , \"iconUri\" : \"/login/assets/pf.png\" }, \"keys\" : [ { \"p\" : \"...\" , \"kty\" : \"RSA\" , \"q\" : \"...\" , \"d\" : \"...\" , \"e\" : \"AQAB\" , \"use\" : \"enc\" , \"kid\" : \"2020-11-20\" , \"qi\" : \"...\" , \"dp\" : \"...\" , \"dq\" : \"...\" , \"n\" : \"...\" } ] } In this example the openid , email , and profile scopes are requested. Additional scopes may be requested. Consult your provider's documentation regarding exposing scopes to clients. The profile and email scopes are required to populate first name, last name, and email fields in the SystemLink user preferences. These are derived from the given_name , family_name , and email claims respectively. Each scope contains claims you can map to roles within SystemLink workspaces. See Mapping OpenID Connect Claims to SystemLink Workspaces and Roles for details. The ni-attributes section determines the text and (optionally) an icon to be shown in the SystemLink login page. The iconUri is relative to the htdocs directory ( C:\\Program Files\\National Instruments\\Shared\\Web Server\\htdocs ). This icon should be 16x16 px. SystemLink login windows with SSO login option. An icon has not been set in this example The keys section contains the private keys as a JWK Set if the provider uses asymmetric encryption for ID token key management. The corresponding public keys must be registered with the provider. The use property must have a value of enc to indicate the key is used for encryption. The kid property of the private key must match the kid property of the corresponding public key on the identity provider. The keys section can be omitted if the provider uses symmetric encryption or no encryption for ID token key management. ClientID and Secret \u00b6 The [provider-issuer-uri].client file is used by the NI Web Server to authenticate with the provider. { \"client_id\" : \"slserver\" , \"client_secret\" : \"4vFm89u07xaredactedredactedredactede2tjtsEGQhlLreLVjcyLA0\" } The client_id and client_secret can be obtained from the provider. Depending on the provider the client_id may be user defined. ClientID and Secret Provider Documentation \u00b6 PingFederate - Configuring an OAuth Client Using OAuth 2.0 to Access Google APIs Okta - Find your Application's credentials ADFS - Build a server side application using OAuth confidential clients with AD FS 2016 or later OpenID Connect Configuration and Discovery \u00b6 The [provider-issuer-uri].provider file includes the contents of the provider's OpenID Connect configuration. This file tells SystemLink which endpoints the provider exposes that are used during login. You may use curl to create this file. Replace [provider-issuer-uri] with the issuer URI of your OpenID Connect Provider. curl https:// [ provider-issuer-uri ] /.well-known/openid-configuration -o [ provider-issuer-uri ] .provider Setting Login Redirect URI \u00b6 The client configuration for your provider requires a redirect URL that is used during the login flow. This must be the fully qualified domain name, the protocol ( https:// or http:// ), and the port (if 80 or 443 are not used) of the SystemLink server. If the SystemLink server's DNS changes, update this setting with your provider. Note NI recommends the DNS name in the redirect URI match the the preferred hostname set in NI Web Server Configuration on the SystemLink server. The SystemLink login redirect URL \u00b6 Use the following URL to configure the login redirect url for your provider: [protocol]://[systemlink-dns]/login/openidc-redirect The SystemLink front channel logout URL \u00b6 This configuration is optional for OpenID Connect providers who support front channel logout. Use the following URL to configure the front channel logout URL your provider: [protocol]://[systemlink-dns]/login/openidc-redirect?logout=get Provider Client Configuration Documentation \u00b6 PingFederate - Configure an OAuth client Google - Using OAuth 2.0 for Web Server Applications Okta - Understand the callback route Proxy Configuration \u00b6 If a proxy is required for the SystemLink server to connect to the OIDC provider, do the following. Create a new file named 60_openidc_proxy.conf in the C:\\Program Files\\National Instruments\\Shared\\Web Server\\conf\\conf.d folder. Add the following text to the file, replacing <host> and <port> with the address of the proxy. <IfDefine AUTH_OIDC_ENABLED > OIDCOutgoingProxy <host> : <port> </IfDefine> Restart the NI Web Server to apply this change. Supported Signing and Encryption Algorithms \u00b6 SystemLink supports the following algorithms for ID token signing, ID token key management encryption, and ID token content encryption. ID Token Signing Algorithm \u00b6 None ECDSA Using P256 Curve and SHA-256 ECDSA Using P384 Curve and SHA-384 ECDSA Using P521 Curve and SHA-512 HMAC using SHA-256 HMAC using SHA-384 HMAC using SHA-512 RSA using SHA-256 RSA using SHA-384 RSA using SHA-512 RSASSA-PSS using SHA-256 RSASSA-PSS using SHA-384 RSASSA-PSS using SHA-512 ID Token Key Management Encryption Algorithm \u00b6 Algorithms that do not require a private key: No encryption Direct Encryption with symmetric key AES-128 Key Wrap AES-192 Key Wrap AES-256 Key Wrap Algorithms that require a private key: RSAES OAEP ECDH-ES Refer to SystemLink Login Configuration for information on configuring the private key. ID Token Content Encryption Algorithm \u00b6 Composite AES-CBC-128 HMAC-SHA-256 Composite AES-CBC-192 HMAC-SHA-384 Composite AES-CBC-256 HMAC-SHA-512 Mapping OpenID Connect Claims to SystemLink Workspaces and Roles \u00b6 Map OpenID Connect claims to roles and workspaces so users can access systems and data managed by SystemLink. This process is the same as the mapping workflow for LDAP and Active Directory attributes. Refer to Assigning Users to Roles in a Workspace in the SystemLink manual. You can also use claims to create a mapping for the Server Administrator role. Viewing Claims Returned by a Provider \u00b6 The OpenID Connect provider determines which scopes and claims clients can access. To see available claims, use the userinfo_endpoint hosted by the provider. Use https://[provider-issuer-uri]/.well-known/openid-configuration to determine the URL of the userinfo_endpoint . You will need to obtain a valid bearer token to authenticate and access this endpoint. Example curl request to return user info. The bearer token has been truncated for readability. curl -s https://slsso-runtime.com/idp/userinfo.openid -H 'Authorization: Bearer eyJhbGciOiJSUzI1NiI...zJVy2oLnrBmXTmpDRm499U4~' | python -m json.tool You can also view claims returned by a particular user by modifying the httpd configuration on your SystemLink server. Go to C:\\Program Files\\National Instruments\\Shared\\Web Server\\conf\\defines.d\\ and open 50_mod_auth_openidc-defines.conf in a text editor. Change the configuration UnDefine AUTH_OIDC_ENABLE_CLAIM_INFO to Define AUTH_OIDC_ENABLE_CLAIM_INFO . Restart NI Web Server. Go to [protocol]://[systemlink-dns]/login/openidc-redirect?info=html or [protocol]://[systemlink-dns]/login/openidc-redirect?info=json to view user claims. An example 50_mod_auth_openidc-defines.conf modified to expose user claims. You must be logged via OpenID Connect to receive data from this endpoint. # # Defined OpenID-Connect configuration for the Windows Apache installation. # # The name of the JSON map containing metadata about each identity provider. Define AUTH_OIDC_ATTRIBUTES_KEY ni-attributes # CA bundle to use when making requests to an identity provider. Define AUTH_OIDC_BUNDLE ../nicurl/ca-bundle.crt # Path to OIDC provider configuration. Define AUTH_OIDC_PROVIDER_DIR ${HTCONF_PATH}/openidc # The location to redirect when performing an OpenID-Connect login. Define AUTH_OIDC_REDIRECT_URI /login/openidc-redirect # # User-editable variables. # # Whether OIDC is enabled. Define AUTH_OIDC_ENABLED # When enabled, /login/openidc-redirect?info=json and # /login/openidc-redirect?info=html will return the claims for the currently # logged in user. Define AUTH_OIDC_ENABLE_CLAIM_INFO If the provider is https with a certificate signed by a CA not included in the NI-CURL CA bundle ( C:\\Program Files\\National Instruments\\Shared\\nicurl\\ca-bundle.crt ), then the AUTH_OIDC_BUNDLE define in 50_mod_auth_openidc-defines.conf must to be updated to point to a CA bundle containing the provider's CA. The path can be absolute, or relative to C:\\Program Files\\National Instruments\\Shared\\Web Server . Mapping Claims to SystemLink Roles \u00b6 Claims are returned as a JSON object. Example response from userinfo_endpoint . Use any of these claims to a map a user to a role in a workspace. { \"email\" : \"jane.doe@ni.com\" , \"family_name\" : \"Doe\" , \"given_name\" : \"Jane\" , \"name\" : \"Jane Doe\" , \"ni_employee\" : \"2670\" , \"sub\" : \"jdoe\" } Within the Access Control application the claim and its returned value can be mapped to a role within a workspace. Mapping the ni_employee claim to a workspace. If the claim value is a scalar, then it must exactly match the value specified in the role mapping. If the claim value is an array, then one of the array elements must exactly match the value specified in the role mappings. If the claim value contains quotes the quotes must be escaped with \\. Example claim containing quotes { \"userinfo\" : { \"sub\" : \"88442211\" , \"country\" : \"US\" , \"name\" : \"Bob Smith\" , \"http://www.example.come/roles\" : [ \"user\" , \"a\\\"b\" ] } } Claims must be escaped with the \\ character. Refreshing user claims \u00b6 Claims are fetched at login. Log out and log back in for updated claims to affect role mappings. Configuring the SystemLink Username \u00b6 Note The username can be configured in SystemLink 2021R1 and later. SystemLink creates a unique username for each user using OpenID Connect claims. SystemLink uses the sub and iss claims by default to ensure that the value is unique across all providers. However those claims often contain internal IDs or URLs from the provider. The default username for an OpenID Connect user may contain internal IDs or URLs. You can change the claim that SystemLink uses as the username. Warn To avoid creating duplicate users and losing per-user settings, configure the username before users begin using the server. Go to C:\\Program Files\\National Instruments\\Shared\\Web Server\\conf\\defines.d and open 50_mod_auth_openidc-defines.conf in a text editor. Find the line UnDefine AUTH_OIDC_USER_CLAIM . Replace UnDefine with Define . Append the name of the claim that SystemLink should use as the username. Note The username must be unique across all enabled providers, including OpenID Connect, LDAP, Windows, and Web Server users. Refer to Viewing Claims Returned by a Provider for information on how to see available claims. Restart the NI Web Server to apply changes. Example An example 50_mod_auth_openidc-defines.conf modified to use the OpenID Connect email claim as the SystemLink username. # # Defined OpenID-Connect configuration for the Windows Apache installation. # # The name of the JSON map containing metadata about each identity provider. Define AUTH_OIDC_ATTRIBUTES_KEY ni-attributes # CA bundle to use when making requests to an identity provider. Define AUTH_OIDC_BUNDLE ../nicurl/ca-bundle.crt # Override the OIDCCacheShmEntrySizeMax to mitigate claim size issues Define AUTH_OIDC_CACHE_ENTRY_SIZE 66065 # Path to OIDC provider configuration. Define AUTH_OIDC_PROVIDER_DIR ${HTCONF_PATH}/openidc # The location to redirect when performing an OpenID-Connect login. Define AUTH_OIDC_REDIRECT_URI /login/openidc-redirect # # User-editable variables. # # Whether OIDC is enabled. Define AUTH_OIDC_ENABLED # The claim that will be used as the SystemLink user name. # If not defined, a combination of the sub and iss claims will be used. Define AUTH_OIDC_USER_CLAIM email # When enabled, /login/openidc-redirect?info=json and # /login/openidc-redirect?info=html will return the claims for the currently # logged in user. UnDefine AUTH_OIDC_ENABLE_CLAIM_INFO Troubleshooting Failed Authentication \u00b6 The following sources can be used to troubleshoot a failed connection. OpenID Connect Provider logs: Consult your OpenID Connect Provider's documentation on the location of their application log files. NI Web Server Logs: These are found at C:\\ProgramData\\National Instruments\\Web Server\\logs . Note SystemLink uses log rotation. Beginning with SystemLink 2021R1, look for error.current.log to find the latest errors. For versions of SystemLink prior to 2021R1, find the latest errors by locating the numbered error.log file with the most recent modified date. Returned Claims: See Viewing Claims Returned by a Provider . Cache Entry Size \u00b6 The OpenID Connect module stores information in a shared memory cache. If a cache entry is too large, users will see an \"Internal Server Error\" when attempting to log in. This typically occurs when you are returning a large number of claims or claims with large values. Example error logs When this happens, the NI Web Server error logs will contain entries like the following: oidc_cache_shm_set: could not store value since value size is too large oidc_cache_set: could NOT store X bytes in shm cache backend for key Y To resolve this issue: Open the following file in a text editor run as Administrator: C:\\Program Files\\National Instruments\\Shared\\Web Server\\conf\\defines.d\\50_mod_auth_openidc-defines.conf Find the line starting with Define AUTH_OIDC_CACHE_ENTRY_SIZE . Modify the number at the end to a number larger than X, where X is the required size of the cache entry specified in the error log. Restart the NI Web Server from the Control tab of the NI Web Server Configuration application. ID Token Management Encryption \u00b6 The following situations can lead to an error and redirect the user back to the SystemLink login page after authenticating with the OpenID Connect provider: The provider is using an asymmetric ID token management encryption algorithm and private keys are missing or incorrect The provider is using an unsupported ID token management encryption algorithm Example error logs The error will be reported in the NI Web Server error logs: oidc_proto_parse_idtoken: oidc_jwt_parse failed The log entry will also contain more information about the problem. To resolve this issue: Confirm that the provider is using supported encryption and signing algorithms. See Supported Signing and Encryption Algorithms . Consult your provider's documentation for information on setting the encryption and signing algorithms. If the provider is using asymmetric ID token management encryption, confirm that the private key is configured in [provider-issuer-uri].conf and the corresponding public key is configured in the provider. Refer to SystemLink Login Configuration for information on configuring the private key. Consult your provider's documentation for information on configuring the ID token management encryption algorithm and public key.","title":"Single Sign-on with OpenID Connect"},{"location":"openid-connect/openid-connect/#single-sign-on-with-openid-connect","text":"You can configure SystemLink to use OpenID Connect to authorize users. This enables SystemLink to use a common identity for users across multiple applications. This also means SystemLink leverages corporate single sign-on (SSO) and all its security benefits, such as streamlined login and limiting user credential proliferation. You can use OpenID Connect alongside or as a replacement for LDAP, Active Directory, and local Windows accounts for authentication.","title":"Single Sign-on with OpenID Connect"},{"location":"openid-connect/openid-connect/#assumptions-and-prerequisites","text":"A server running SystemLink 2020R4 or greater. Refer to Installing and Configuring SystemLink Server and Clients for the basics of setting up a SystemLink server An active Advanced Server license for the SystemLink server. If the license is inactive or expires, users will be able to log in with OpenID Connect, but they will not have any permissions and will see a blank page. A DNS name for the SystemLink server SystemLink login with the Server Administrator role Administrator desktop access to the SystemLink server An OpenID Connect Provider server such as PingFederate , Azure ADFS , Okta , or another certified provider that has been fully set up and configured for OpenID Connect authentication","title":"Assumptions and Prerequisites"},{"location":"openid-connect/openid-connect/#enabling-openid-connect-in-systemlink","text":"Log into the server running SystemLink and go to C:\\Program Files\\National Instruments\\Shared\\Web Server\\conf\\openidc . Add the configuration files to SystemLink to connect to your OpenID Connect provider. For details, refer to OpenID Connect Configuration Files in SystemLink Server . In SystemLink 2021R1 and later, configure the claim to use as the SystemLink username. This step is optional, but should be done before users begin using the server. For details, refer to Configuring the SystemLink Username . Open NI Web Server Configuration . Go to the Authentication tab and enable Use OpenID Connect (advanced) . Click Apply and restart . Log into the SystemLink web application with a user assigned the Server Administrator role. Go to Access Control > Roles and click the gear icon in the top right. Add an OpenID Connect Claim mapping for the Server Administrator role. For details, refer to Mapping OpenID Connect Claims to SystemLink Workspaces and Roles . Log out and log in as an OpenID Connect user with a mapping for the Server Administrator role and confirm they have the correct privileges. Enable OpenID Connect in NI Web Server","title":"Enabling OpenID Connect in SystemLink"},{"location":"openid-connect/openid-connect/#openid-connect-configuration-files-in-systemlink-server","text":"There are three files that you must create to connect your SystemLink server to an OpenID Connect provider: [provider-issuer-uri].conf , [provider-issuer-uri].client , and [provider-issuer-uri].provider . The [provider-issuer-uri] portion of each filename must be the URL-encoded fully qualified domain name. Refer to openid-connect-config for examples of each of these files. Example An OpenID Connect provider with the issuer URI example.com:9999/v2 would yield files named example.com%3A9999%2Fv2.conf , example.com%3A9999%2Fv2.client , and example.com%3A9999%2Fv2.provider . You can find the issuer URI by viewing the issuer property at your provider's OpenID Connect configuration endpoint. For example https://example.com:9999/v2/.well-known/openid-configuration . These files do not exist for new SystemLink installations. Add each file to C:\\Program Files\\National Instruments\\Shared\\Web Server\\conf\\openidc . Restart the NI Web Server to apply changes. You can configure SystemLink to support multiple OpenID Connect providers simultaneously by creating a [provider-issuer-uri].conf , [provider-issuer-uri.client , and [provider-issuer-uri].provider file for each provider. The user ID in SystemLink must be unique across providers. This ID takes the form [sub_claim]@issuer . You can see the ID SystemLink associates with a user in the user details in SystemLink Access Control.","title":"OpenID Connect Configuration Files in SystemLink Server"},{"location":"openid-connect/openid-connect/#systemlink-login-configuration","text":"[provider-issuer-uri].conf describes the scopes SystemLink will request, the text and icon for the provider login button, and private keys for ID token key management encryption. { \"scope\" : \"openid email profile\" , \"ni-attributes\" : { \"displayName\" : \"Log in with PingFederate\" , \"iconUri\" : \"/login/assets/pf.png\" }, \"keys\" : [ { \"p\" : \"...\" , \"kty\" : \"RSA\" , \"q\" : \"...\" , \"d\" : \"...\" , \"e\" : \"AQAB\" , \"use\" : \"enc\" , \"kid\" : \"2020-11-20\" , \"qi\" : \"...\" , \"dp\" : \"...\" , \"dq\" : \"...\" , \"n\" : \"...\" } ] } In this example the openid , email , and profile scopes are requested. Additional scopes may be requested. Consult your provider's documentation regarding exposing scopes to clients. The profile and email scopes are required to populate first name, last name, and email fields in the SystemLink user preferences. These are derived from the given_name , family_name , and email claims respectively. Each scope contains claims you can map to roles within SystemLink workspaces. See Mapping OpenID Connect Claims to SystemLink Workspaces and Roles for details. The ni-attributes section determines the text and (optionally) an icon to be shown in the SystemLink login page. The iconUri is relative to the htdocs directory ( C:\\Program Files\\National Instruments\\Shared\\Web Server\\htdocs ). This icon should be 16x16 px. SystemLink login windows with SSO login option. An icon has not been set in this example The keys section contains the private keys as a JWK Set if the provider uses asymmetric encryption for ID token key management. The corresponding public keys must be registered with the provider. The use property must have a value of enc to indicate the key is used for encryption. The kid property of the private key must match the kid property of the corresponding public key on the identity provider. The keys section can be omitted if the provider uses symmetric encryption or no encryption for ID token key management.","title":"SystemLink Login Configuration"},{"location":"openid-connect/openid-connect/#clientid-and-secret","text":"The [provider-issuer-uri].client file is used by the NI Web Server to authenticate with the provider. { \"client_id\" : \"slserver\" , \"client_secret\" : \"4vFm89u07xaredactedredactedredactede2tjtsEGQhlLreLVjcyLA0\" } The client_id and client_secret can be obtained from the provider. Depending on the provider the client_id may be user defined.","title":"ClientID and Secret"},{"location":"openid-connect/openid-connect/#clientid-and-secret-provider-documentation","text":"PingFederate - Configuring an OAuth Client Using OAuth 2.0 to Access Google APIs Okta - Find your Application's credentials ADFS - Build a server side application using OAuth confidential clients with AD FS 2016 or later","title":"ClientID and Secret Provider Documentation"},{"location":"openid-connect/openid-connect/#openid-connect-configuration-and-discovery","text":"The [provider-issuer-uri].provider file includes the contents of the provider's OpenID Connect configuration. This file tells SystemLink which endpoints the provider exposes that are used during login. You may use curl to create this file. Replace [provider-issuer-uri] with the issuer URI of your OpenID Connect Provider. curl https:// [ provider-issuer-uri ] /.well-known/openid-configuration -o [ provider-issuer-uri ] .provider","title":"OpenID Connect Configuration and Discovery"},{"location":"openid-connect/openid-connect/#setting-login-redirect-uri","text":"The client configuration for your provider requires a redirect URL that is used during the login flow. This must be the fully qualified domain name, the protocol ( https:// or http:// ), and the port (if 80 or 443 are not used) of the SystemLink server. If the SystemLink server's DNS changes, update this setting with your provider. Note NI recommends the DNS name in the redirect URI match the the preferred hostname set in NI Web Server Configuration on the SystemLink server.","title":"Setting Login Redirect URI"},{"location":"openid-connect/openid-connect/#the-systemlink-login-redirect-url","text":"Use the following URL to configure the login redirect url for your provider: [protocol]://[systemlink-dns]/login/openidc-redirect","title":"The SystemLink login redirect URL"},{"location":"openid-connect/openid-connect/#the-systemlink-front-channel-logout-url","text":"This configuration is optional for OpenID Connect providers who support front channel logout. Use the following URL to configure the front channel logout URL your provider: [protocol]://[systemlink-dns]/login/openidc-redirect?logout=get","title":"The SystemLink front channel logout URL"},{"location":"openid-connect/openid-connect/#provider-client-configuration-documentation","text":"PingFederate - Configure an OAuth client Google - Using OAuth 2.0 for Web Server Applications Okta - Understand the callback route","title":"Provider Client Configuration Documentation"},{"location":"openid-connect/openid-connect/#proxy-configuration","text":"If a proxy is required for the SystemLink server to connect to the OIDC provider, do the following. Create a new file named 60_openidc_proxy.conf in the C:\\Program Files\\National Instruments\\Shared\\Web Server\\conf\\conf.d folder. Add the following text to the file, replacing <host> and <port> with the address of the proxy. <IfDefine AUTH_OIDC_ENABLED > OIDCOutgoingProxy <host> : <port> </IfDefine> Restart the NI Web Server to apply this change.","title":"Proxy Configuration"},{"location":"openid-connect/openid-connect/#supported-signing-and-encryption-algorithms","text":"SystemLink supports the following algorithms for ID token signing, ID token key management encryption, and ID token content encryption.","title":"Supported Signing and Encryption Algorithms"},{"location":"openid-connect/openid-connect/#id-token-signing-algorithm","text":"None ECDSA Using P256 Curve and SHA-256 ECDSA Using P384 Curve and SHA-384 ECDSA Using P521 Curve and SHA-512 HMAC using SHA-256 HMAC using SHA-384 HMAC using SHA-512 RSA using SHA-256 RSA using SHA-384 RSA using SHA-512 RSASSA-PSS using SHA-256 RSASSA-PSS using SHA-384 RSASSA-PSS using SHA-512","title":"ID Token Signing Algorithm"},{"location":"openid-connect/openid-connect/#id-token-key-management-encryption-algorithm","text":"Algorithms that do not require a private key: No encryption Direct Encryption with symmetric key AES-128 Key Wrap AES-192 Key Wrap AES-256 Key Wrap Algorithms that require a private key: RSAES OAEP ECDH-ES Refer to SystemLink Login Configuration for information on configuring the private key.","title":"ID Token Key Management Encryption Algorithm"},{"location":"openid-connect/openid-connect/#id-token-content-encryption-algorithm","text":"Composite AES-CBC-128 HMAC-SHA-256 Composite AES-CBC-192 HMAC-SHA-384 Composite AES-CBC-256 HMAC-SHA-512","title":"ID Token Content Encryption Algorithm"},{"location":"openid-connect/openid-connect/#mapping-openid-connect-claims-to-systemlink-workspaces-and-roles","text":"Map OpenID Connect claims to roles and workspaces so users can access systems and data managed by SystemLink. This process is the same as the mapping workflow for LDAP and Active Directory attributes. Refer to Assigning Users to Roles in a Workspace in the SystemLink manual. You can also use claims to create a mapping for the Server Administrator role.","title":"Mapping OpenID Connect Claims to SystemLink Workspaces and Roles"},{"location":"openid-connect/openid-connect/#viewing-claims-returned-by-a-provider","text":"The OpenID Connect provider determines which scopes and claims clients can access. To see available claims, use the userinfo_endpoint hosted by the provider. Use https://[provider-issuer-uri]/.well-known/openid-configuration to determine the URL of the userinfo_endpoint . You will need to obtain a valid bearer token to authenticate and access this endpoint. Example curl request to return user info. The bearer token has been truncated for readability. curl -s https://slsso-runtime.com/idp/userinfo.openid -H 'Authorization: Bearer eyJhbGciOiJSUzI1NiI...zJVy2oLnrBmXTmpDRm499U4~' | python -m json.tool You can also view claims returned by a particular user by modifying the httpd configuration on your SystemLink server. Go to C:\\Program Files\\National Instruments\\Shared\\Web Server\\conf\\defines.d\\ and open 50_mod_auth_openidc-defines.conf in a text editor. Change the configuration UnDefine AUTH_OIDC_ENABLE_CLAIM_INFO to Define AUTH_OIDC_ENABLE_CLAIM_INFO . Restart NI Web Server. Go to [protocol]://[systemlink-dns]/login/openidc-redirect?info=html or [protocol]://[systemlink-dns]/login/openidc-redirect?info=json to view user claims. An example 50_mod_auth_openidc-defines.conf modified to expose user claims. You must be logged via OpenID Connect to receive data from this endpoint. # # Defined OpenID-Connect configuration for the Windows Apache installation. # # The name of the JSON map containing metadata about each identity provider. Define AUTH_OIDC_ATTRIBUTES_KEY ni-attributes # CA bundle to use when making requests to an identity provider. Define AUTH_OIDC_BUNDLE ../nicurl/ca-bundle.crt # Path to OIDC provider configuration. Define AUTH_OIDC_PROVIDER_DIR ${HTCONF_PATH}/openidc # The location to redirect when performing an OpenID-Connect login. Define AUTH_OIDC_REDIRECT_URI /login/openidc-redirect # # User-editable variables. # # Whether OIDC is enabled. Define AUTH_OIDC_ENABLED # When enabled, /login/openidc-redirect?info=json and # /login/openidc-redirect?info=html will return the claims for the currently # logged in user. Define AUTH_OIDC_ENABLE_CLAIM_INFO If the provider is https with a certificate signed by a CA not included in the NI-CURL CA bundle ( C:\\Program Files\\National Instruments\\Shared\\nicurl\\ca-bundle.crt ), then the AUTH_OIDC_BUNDLE define in 50_mod_auth_openidc-defines.conf must to be updated to point to a CA bundle containing the provider's CA. The path can be absolute, or relative to C:\\Program Files\\National Instruments\\Shared\\Web Server .","title":"Viewing Claims Returned by a Provider"},{"location":"openid-connect/openid-connect/#mapping-claims-to-systemlink-roles","text":"Claims are returned as a JSON object. Example response from userinfo_endpoint . Use any of these claims to a map a user to a role in a workspace. { \"email\" : \"jane.doe@ni.com\" , \"family_name\" : \"Doe\" , \"given_name\" : \"Jane\" , \"name\" : \"Jane Doe\" , \"ni_employee\" : \"2670\" , \"sub\" : \"jdoe\" } Within the Access Control application the claim and its returned value can be mapped to a role within a workspace. Mapping the ni_employee claim to a workspace. If the claim value is a scalar, then it must exactly match the value specified in the role mapping. If the claim value is an array, then one of the array elements must exactly match the value specified in the role mappings. If the claim value contains quotes the quotes must be escaped with \\. Example claim containing quotes { \"userinfo\" : { \"sub\" : \"88442211\" , \"country\" : \"US\" , \"name\" : \"Bob Smith\" , \"http://www.example.come/roles\" : [ \"user\" , \"a\\\"b\" ] } } Claims must be escaped with the \\ character.","title":"Mapping Claims to SystemLink Roles"},{"location":"openid-connect/openid-connect/#refreshing-user-claims","text":"Claims are fetched at login. Log out and log back in for updated claims to affect role mappings.","title":"Refreshing user claims"},{"location":"openid-connect/openid-connect/#configuring-the-systemlink-username","text":"Note The username can be configured in SystemLink 2021R1 and later. SystemLink creates a unique username for each user using OpenID Connect claims. SystemLink uses the sub and iss claims by default to ensure that the value is unique across all providers. However those claims often contain internal IDs or URLs from the provider. The default username for an OpenID Connect user may contain internal IDs or URLs. You can change the claim that SystemLink uses as the username. Warn To avoid creating duplicate users and losing per-user settings, configure the username before users begin using the server. Go to C:\\Program Files\\National Instruments\\Shared\\Web Server\\conf\\defines.d and open 50_mod_auth_openidc-defines.conf in a text editor. Find the line UnDefine AUTH_OIDC_USER_CLAIM . Replace UnDefine with Define . Append the name of the claim that SystemLink should use as the username. Note The username must be unique across all enabled providers, including OpenID Connect, LDAP, Windows, and Web Server users. Refer to Viewing Claims Returned by a Provider for information on how to see available claims. Restart the NI Web Server to apply changes. Example An example 50_mod_auth_openidc-defines.conf modified to use the OpenID Connect email claim as the SystemLink username. # # Defined OpenID-Connect configuration for the Windows Apache installation. # # The name of the JSON map containing metadata about each identity provider. Define AUTH_OIDC_ATTRIBUTES_KEY ni-attributes # CA bundle to use when making requests to an identity provider. Define AUTH_OIDC_BUNDLE ../nicurl/ca-bundle.crt # Override the OIDCCacheShmEntrySizeMax to mitigate claim size issues Define AUTH_OIDC_CACHE_ENTRY_SIZE 66065 # Path to OIDC provider configuration. Define AUTH_OIDC_PROVIDER_DIR ${HTCONF_PATH}/openidc # The location to redirect when performing an OpenID-Connect login. Define AUTH_OIDC_REDIRECT_URI /login/openidc-redirect # # User-editable variables. # # Whether OIDC is enabled. Define AUTH_OIDC_ENABLED # The claim that will be used as the SystemLink user name. # If not defined, a combination of the sub and iss claims will be used. Define AUTH_OIDC_USER_CLAIM email # When enabled, /login/openidc-redirect?info=json and # /login/openidc-redirect?info=html will return the claims for the currently # logged in user. UnDefine AUTH_OIDC_ENABLE_CLAIM_INFO","title":"Configuring the SystemLink Username"},{"location":"openid-connect/openid-connect/#troubleshooting-failed-authentication","text":"The following sources can be used to troubleshoot a failed connection. OpenID Connect Provider logs: Consult your OpenID Connect Provider's documentation on the location of their application log files. NI Web Server Logs: These are found at C:\\ProgramData\\National Instruments\\Web Server\\logs . Note SystemLink uses log rotation. Beginning with SystemLink 2021R1, look for error.current.log to find the latest errors. For versions of SystemLink prior to 2021R1, find the latest errors by locating the numbered error.log file with the most recent modified date. Returned Claims: See Viewing Claims Returned by a Provider .","title":"Troubleshooting Failed Authentication"},{"location":"openid-connect/openid-connect/#cache-entry-size","text":"The OpenID Connect module stores information in a shared memory cache. If a cache entry is too large, users will see an \"Internal Server Error\" when attempting to log in. This typically occurs when you are returning a large number of claims or claims with large values. Example error logs When this happens, the NI Web Server error logs will contain entries like the following: oidc_cache_shm_set: could not store value since value size is too large oidc_cache_set: could NOT store X bytes in shm cache backend for key Y To resolve this issue: Open the following file in a text editor run as Administrator: C:\\Program Files\\National Instruments\\Shared\\Web Server\\conf\\defines.d\\50_mod_auth_openidc-defines.conf Find the line starting with Define AUTH_OIDC_CACHE_ENTRY_SIZE . Modify the number at the end to a number larger than X, where X is the required size of the cache entry specified in the error log. Restart the NI Web Server from the Control tab of the NI Web Server Configuration application.","title":"Cache Entry Size"},{"location":"openid-connect/openid-connect/#id-token-management-encryption","text":"The following situations can lead to an error and redirect the user back to the SystemLink login page after authenticating with the OpenID Connect provider: The provider is using an asymmetric ID token management encryption algorithm and private keys are missing or incorrect The provider is using an unsupported ID token management encryption algorithm Example error logs The error will be reported in the NI Web Server error logs: oidc_proto_parse_idtoken: oidc_jwt_parse failed The log entry will also contain more information about the problem. To resolve this issue: Confirm that the provider is using supported encryption and signing algorithms. See Supported Signing and Encryption Algorithms . Consult your provider's documentation for information on setting the encryption and signing algorithms. If the provider is using asymmetric ID token management encryption, confirm that the private key is configured in [provider-issuer-uri].conf and the corresponding public key is configured in the provider. Refer to SystemLink Login Configuration for information on configuring the private key. Consult your provider's documentation for information on configuring the ID token management encryption algorithm and public key.","title":"ID Token Management Encryption"},{"location":"preview-features/preview-features/","text":"Preview Features \u00b6 This section contains guided help for preview features in the current SystemLink release. While preview features are not yet complete and have limited functionality, they provide an understanding of the direction the product is taking and give users the opportunity to experiment and give feedback. Creating and Uploading Analysis Automation Procedures with Jupyter Notebooks \u00b6 Analysis Automation performs recurring analyses with similar data and exports the results as a PDF or graphics file for management reporting. Analysis automation procedures define the analyses and contain the analysis script, the parameter definition, and the search query for the respective data. Currently, you create procedures in DIAdem VBS or Python, but now you can also create them in Jupyter and upload them straight to Analyis Automation. Prerequisites \u00b6 To create analysis automation procedures with Jupyter in SystemLink, you need to install SystemLink 2021 R1 and the Measurement Data Analysis and Jupyter Hub modules. Steps to Take \u00b6 Create an analysis automation procedure from the analysis notebook you write in Jupyter and upload it to the procedures library in Analysis Automation. In Jupyter , open the analysis notebook you want to upload. Right-click the notebook and select New Analysis Automation Procedure . Create a new analysis automation procedure from the notebook. In the dialog box, specify the following information: Enter a name and description for the procedure. Choose a Workspace to define the users and the available data sources that can interact with the procedure. In the dropdown menu, choose a Search Query you saved in Data Navigation. The query defines the data you want to analyze with the analysis notebook. Verify that the data sources in the query are in the workspace you chose. Select the Execution Mode . Select Compare if you want to run the analysis notebook on all data elements the search query retrieves. Select Parallel if you want to run the analysis notebook on each data element the search query retrieves. Click OK . The procedure uploads to Analysis Automation. Click the Analysis Automation link to view the procedure on the Procedures tab in Analysis Automation. Approve the procedure for it to go live. Note: Approving procedures requires the Approve and reject procedures privilege. After uploading the procedure, add a task to execute your procedure in Analysis Automation .","title":"Preview Features"},{"location":"preview-features/preview-features/#preview-features","text":"This section contains guided help for preview features in the current SystemLink release. While preview features are not yet complete and have limited functionality, they provide an understanding of the direction the product is taking and give users the opportunity to experiment and give feedback.","title":"Preview Features"},{"location":"preview-features/preview-features/#creating-and-uploading-analysis-automation-procedures-with-jupyter-notebooks","text":"Analysis Automation performs recurring analyses with similar data and exports the results as a PDF or graphics file for management reporting. Analysis automation procedures define the analyses and contain the analysis script, the parameter definition, and the search query for the respective data. Currently, you create procedures in DIAdem VBS or Python, but now you can also create them in Jupyter and upload them straight to Analyis Automation.","title":"Creating and Uploading Analysis Automation Procedures with Jupyter Notebooks"},{"location":"preview-features/preview-features/#prerequisites","text":"To create analysis automation procedures with Jupyter in SystemLink, you need to install SystemLink 2021 R1 and the Measurement Data Analysis and Jupyter Hub modules.","title":"Prerequisites"},{"location":"preview-features/preview-features/#steps-to-take","text":"Create an analysis automation procedure from the analysis notebook you write in Jupyter and upload it to the procedures library in Analysis Automation. In Jupyter , open the analysis notebook you want to upload. Right-click the notebook and select New Analysis Automation Procedure . Create a new analysis automation procedure from the notebook. In the dialog box, specify the following information: Enter a name and description for the procedure. Choose a Workspace to define the users and the available data sources that can interact with the procedure. In the dropdown menu, choose a Search Query you saved in Data Navigation. The query defines the data you want to analyze with the analysis notebook. Verify that the data sources in the query are in the workspace you chose. Select the Execution Mode . Select Compare if you want to run the analysis notebook on all data elements the search query retrieves. Select Parallel if you want to run the analysis notebook on each data element the search query retrieves. Click OK . The procedure uploads to Analysis Automation. Click the Analysis Automation link to view the procedure on the Procedures tab in Analysis Automation. Approve the procedure for it to go live. Note: Approving procedures requires the Approve and reject procedures privilege. After uploading the procedure, add a task to execute your procedure in Analysis Automation .","title":"Steps to Take"},{"location":"python-dataplugins/python-dataplugins/","text":"Python DataPlugins \u00b6 Create a DataPlugin to load, register, or search your custom file formats in LabVIEW or DIAdem, or to index, browse, and find your file formats with SystemLink DataFinder. You can also create DataPlugins using C++, VBS, LabVIEW, or Python. Note Browse through 230+ DataPlugins in the NI Store to check whether there is an existing DataPlugin for your data format. Getting Started \u00b6 Python DataPlugins consist of only one Python file that contains all the logic. Almost all language features of the official Python 3.5.9 and its base libraries can be used. You can create Python DataPlugins in your favorite editor. Recommended: NI DIAdem >= 2020 VSCode with the NI Python DataPlugin Extension Plugin Class \u00b6 Start writing your DataPlugin by implementing class Plugin : The class name cannot be changed. Read Store \u00b6 You need to implement a read_store method in every Python DataPlugin. This method is called by DIAdem, LabVIEW, or SystemLink DataFinder when attempting to open your data file. The applications pass a set of useful parameters that can be accessed by the parameter array. Example Code import datetime import os from pathlib import Path def read_store ( self , parameter ): \"\"\" Reads data file and returns a Python dictionary that contains groups and channels in a TDM-like structure. \"\"\" # String: Contains the absolute path to the data file file_path = os . path . realpath ( parameter [ \"file\" ]) # Boolean: Denotes whether data file was accessed by SystemLink DataFinder # => the bulk data was not touched. is_datafinder_indexer = parameter [ \"datafinder\" ] tdm_tree = { \"author\" : \"NI\" , \"description\" : \"File containing a json dict read by Python plugin\" , \"groups\" : [{ \"name\" : \"Group_1\" , \"description\" : \"First group\" , \"channels\" : [{ \"name\" : \"Index\" , \"description\" : \"\" , \"info\" : \"Going up\" , \"unit_string\" : \"s\" , \"type\" : \"DataTypeChnFloat64\" , \"values\" : [ 1 , 2 , 3 ] }, { \"name\" : \"Vals_1\" , \"description\" : \"\" , \"unit_string\" : \"km/h\" , \"type\" : \"DataTypeChnFloat64\" , \"values\" : [ 1.1 , 2.1 , 3.1 ] }, { \"name\" : \"Vals_2\" , \"description\" : \"\" , \"unit_string\" : \"km/h\" , \"type\" : \"DataTypeChnFloat64\" , \"values\" : [ 1.2 , 2.2 , 3.2 ] }, { \"name\" : \"Str_1\" , \"description\" : \"\" , \"type\" : \"DataTypeChnString\" , \"values\" : [ \"abc\" , \"def\" , \"hij\" ] }] }, { \"name\" : \"Group_2\" , \"description\" : \"Second group\" , \"channels\" : [{ \"name\" : \"Index\" , \"description\" : \"\" , \"info\" : \"Going up\" , \"unit_string\" : \"s\" , \"type\" : \"DataTypeChnFloat64\" , \"values\" : [ 1 , 2 , 3 , 4 ] } ] }] } return { Path ( file_path ) . stem : tdm_tree } Use the file parameter to access your file using text, CSV, or binary readers. The data must be added to a Python dictionary. It represents the structure of tdm/tdms files that consists of one root, 0...m groups, and 0...n channels: TDM structure with root, groups, and channels Example dictionary self . tdm_tree = { \"author\" : \"NI\" , \"description\" : \"Example file\" , \"groups\" : [{ \"name\" : \"Example\" , \"description\" : \"First group\" , \"time\" : datetime . datetime ( 2020 , 2 , 11 , 15 , 31 , 59 , 342380 ), \"channels\" : [{ \"name\" : \"Channel_0\" , \"description\" : \"\" , \"values\" : [ 1.2 , 1.3 , 1.4 ], \"info\" : \"Time in seconds\" , \"type\" : \"DataTypeChnFloat64\" }, { \"name\" : \"Channel_1\" , \"description\" : \"\" , \"values\" : [ 10 , 11 , 12 ], \"unit_string\" : \"km/h\" , \"type\" : \"DataTypeChnFloat64\" }] }] } file_path = os . path . realpath ( parameter [ \"file\" ]) return { Path ( file_path ) . stem : self . tdm_tree } Dictionary Schema import datetime from schema import And , Schema Schema ({ Optional ( 'author' ): str , Optional ( 'description' ): str , 'groups' : [{ 'name' : str , Optional ( 'description' ): str , Optional ( 'time' ): datetime . datetime , 'channels' : [{ 'name' : str , Optional ( 'description' ): str , 'values' : list , Optional ( 'unit_string' ): str , 'type' : And ( str , lambda s : s in ( 'DataTypeChnFloat32' , 'DataTypeChnFloat64' , 'DataTypeChnString' , 'DataTypeChnDate' , 'DataTypeChnUInt8' , 'DataTypeChnInt16' , 'DataTypeChnInt32' , 'DataTypeChnInt64' )) }] }]}, ignore_extra_keys = True ) All additional \"extra keys\" will show up as custom properties in DIAdem, Labview, or SystemLink DataFinder. See full example: csv-read-with-direct-loading Callback Loading \u00b6 When handling a big data set, you might not want to load all data at the same time. To ensure the DataPlugin only returns values that applications request: Assign an empty array to the channel values property: ... 'groups' : [{ ... 'channels' : [{ ... 'values' : [], }] }] Outsource the functionality to load the bulk data values in a separate function. The function has the following definition: def read_channel_values ( self , grp_index , chn_index , numberToSkip , numberToTake ): \"\"\" Returns a value array of the correct data type specified in the TDM dictionary \"\"\" Example Code def read_channel_values ( self , grp_index , chn_index , numberToSkip , numberToTake ): dataType = self . tdm_tree [ \"groups\" ][ grp_index ][ \"channels\" ][ chn_index ][ \"type\" ] values = [] for row in self . data : value = row [ self . channelNames [ chn_index ]] values . append ( value ) return values [ numberToSkip : numberToTake + numberToSkip ] The client applications call this function to retrieve channel values (or a subset of values). You need to implement the function to return the values for a given group and channel index. You also need to ensure only the correct subset of values is returned for a given numberToSkip and numberToTake . In addition, you need to implement a callback function to retrieve the channel length. If all channels have the same length, it simply returns a constant. def read_channel_length ( self , grp_index , chn_index ): \"\"\" Returns the channel length as an Integer for a given group and channel index \"\"\" return 10 See full example: csv-read-with-callback-loading Error Handling \u00b6 Python DataPlugins can raise errors in all callback functions. The raised error is displayed in DIAdem, LabVIEW, or SystemLink DataFinder. def read_store ( self , parameter ): ... raise Exception ( \"Leave read_store with exception\" ) Not My File \u00b6 A special case is \"Not My File\". This error should be raised when the DataPlugin detects that the file to be opened is not suited for this DataPlugin. This special error can be raised only in the read_store function by returning None : def read_store ( self , parameter ): ... if notMyFile : return None Export DataPlugin \u00b6 Export Python DataPlugins to make them available on other systems. Use NI DIAdem to export a DataPlugin as a URI file. Exporting DataPlugins in DIAdem You can also export a DataPlugin from NI's Python DataPlugin Extension for Visual Studio Code: Exporting DataPlugins in VSCode Encrypted DataPlugins \u00b6 In some cases, you may want to protect your code from being viewed by others. Use NI DIAdem to export an encrypted Python DataPlugin. This functionality is not available in the VSCode extension. Known Limitations \u00b6 NumPy and Pandas \u00b6 NumPy and Pandas do not run reliably in embedded Python environments and, therefore, NI does not recommend them for use in DataPlugins. Single File DataPlugins \u00b6 Python DataPlugins can only be written in a single Python file. Importing sidecar files is not supported. It will fail when exporting the DataPlugin as a URI. datetime.strptime \u00b6 There is an open issue in Python for datetime.strptime that prevents the function from working properly in embedded Python environments. Avoid using this function in DataPlugin source code. Instead, add the following function to your code: def strptime ( self , value , format ): return datetime . datetime ( * ( time . strptime ( value , \" %d .%m.%y %H:%M:%S\" )[ 0 : 6 ]))","title":"Python DataPlugins"},{"location":"python-dataplugins/python-dataplugins/#python-dataplugins","text":"Create a DataPlugin to load, register, or search your custom file formats in LabVIEW or DIAdem, or to index, browse, and find your file formats with SystemLink DataFinder. You can also create DataPlugins using C++, VBS, LabVIEW, or Python. Note Browse through 230+ DataPlugins in the NI Store to check whether there is an existing DataPlugin for your data format.","title":"Python DataPlugins"},{"location":"python-dataplugins/python-dataplugins/#getting-started","text":"Python DataPlugins consist of only one Python file that contains all the logic. Almost all language features of the official Python 3.5.9 and its base libraries can be used. You can create Python DataPlugins in your favorite editor. Recommended: NI DIAdem >= 2020 VSCode with the NI Python DataPlugin Extension","title":"Getting Started"},{"location":"python-dataplugins/python-dataplugins/#plugin-class","text":"Start writing your DataPlugin by implementing class Plugin : The class name cannot be changed.","title":"Plugin Class"},{"location":"python-dataplugins/python-dataplugins/#read-store","text":"You need to implement a read_store method in every Python DataPlugin. This method is called by DIAdem, LabVIEW, or SystemLink DataFinder when attempting to open your data file. The applications pass a set of useful parameters that can be accessed by the parameter array. Example Code import datetime import os from pathlib import Path def read_store ( self , parameter ): \"\"\" Reads data file and returns a Python dictionary that contains groups and channels in a TDM-like structure. \"\"\" # String: Contains the absolute path to the data file file_path = os . path . realpath ( parameter [ \"file\" ]) # Boolean: Denotes whether data file was accessed by SystemLink DataFinder # => the bulk data was not touched. is_datafinder_indexer = parameter [ \"datafinder\" ] tdm_tree = { \"author\" : \"NI\" , \"description\" : \"File containing a json dict read by Python plugin\" , \"groups\" : [{ \"name\" : \"Group_1\" , \"description\" : \"First group\" , \"channels\" : [{ \"name\" : \"Index\" , \"description\" : \"\" , \"info\" : \"Going up\" , \"unit_string\" : \"s\" , \"type\" : \"DataTypeChnFloat64\" , \"values\" : [ 1 , 2 , 3 ] }, { \"name\" : \"Vals_1\" , \"description\" : \"\" , \"unit_string\" : \"km/h\" , \"type\" : \"DataTypeChnFloat64\" , \"values\" : [ 1.1 , 2.1 , 3.1 ] }, { \"name\" : \"Vals_2\" , \"description\" : \"\" , \"unit_string\" : \"km/h\" , \"type\" : \"DataTypeChnFloat64\" , \"values\" : [ 1.2 , 2.2 , 3.2 ] }, { \"name\" : \"Str_1\" , \"description\" : \"\" , \"type\" : \"DataTypeChnString\" , \"values\" : [ \"abc\" , \"def\" , \"hij\" ] }] }, { \"name\" : \"Group_2\" , \"description\" : \"Second group\" , \"channels\" : [{ \"name\" : \"Index\" , \"description\" : \"\" , \"info\" : \"Going up\" , \"unit_string\" : \"s\" , \"type\" : \"DataTypeChnFloat64\" , \"values\" : [ 1 , 2 , 3 , 4 ] } ] }] } return { Path ( file_path ) . stem : tdm_tree } Use the file parameter to access your file using text, CSV, or binary readers. The data must be added to a Python dictionary. It represents the structure of tdm/tdms files that consists of one root, 0...m groups, and 0...n channels: TDM structure with root, groups, and channels Example dictionary self . tdm_tree = { \"author\" : \"NI\" , \"description\" : \"Example file\" , \"groups\" : [{ \"name\" : \"Example\" , \"description\" : \"First group\" , \"time\" : datetime . datetime ( 2020 , 2 , 11 , 15 , 31 , 59 , 342380 ), \"channels\" : [{ \"name\" : \"Channel_0\" , \"description\" : \"\" , \"values\" : [ 1.2 , 1.3 , 1.4 ], \"info\" : \"Time in seconds\" , \"type\" : \"DataTypeChnFloat64\" }, { \"name\" : \"Channel_1\" , \"description\" : \"\" , \"values\" : [ 10 , 11 , 12 ], \"unit_string\" : \"km/h\" , \"type\" : \"DataTypeChnFloat64\" }] }] } file_path = os . path . realpath ( parameter [ \"file\" ]) return { Path ( file_path ) . stem : self . tdm_tree } Dictionary Schema import datetime from schema import And , Schema Schema ({ Optional ( 'author' ): str , Optional ( 'description' ): str , 'groups' : [{ 'name' : str , Optional ( 'description' ): str , Optional ( 'time' ): datetime . datetime , 'channels' : [{ 'name' : str , Optional ( 'description' ): str , 'values' : list , Optional ( 'unit_string' ): str , 'type' : And ( str , lambda s : s in ( 'DataTypeChnFloat32' , 'DataTypeChnFloat64' , 'DataTypeChnString' , 'DataTypeChnDate' , 'DataTypeChnUInt8' , 'DataTypeChnInt16' , 'DataTypeChnInt32' , 'DataTypeChnInt64' )) }] }]}, ignore_extra_keys = True ) All additional \"extra keys\" will show up as custom properties in DIAdem, Labview, or SystemLink DataFinder. See full example: csv-read-with-direct-loading","title":"Read Store"},{"location":"python-dataplugins/python-dataplugins/#callback-loading","text":"When handling a big data set, you might not want to load all data at the same time. To ensure the DataPlugin only returns values that applications request: Assign an empty array to the channel values property: ... 'groups' : [{ ... 'channels' : [{ ... 'values' : [], }] }] Outsource the functionality to load the bulk data values in a separate function. The function has the following definition: def read_channel_values ( self , grp_index , chn_index , numberToSkip , numberToTake ): \"\"\" Returns a value array of the correct data type specified in the TDM dictionary \"\"\" Example Code def read_channel_values ( self , grp_index , chn_index , numberToSkip , numberToTake ): dataType = self . tdm_tree [ \"groups\" ][ grp_index ][ \"channels\" ][ chn_index ][ \"type\" ] values = [] for row in self . data : value = row [ self . channelNames [ chn_index ]] values . append ( value ) return values [ numberToSkip : numberToTake + numberToSkip ] The client applications call this function to retrieve channel values (or a subset of values). You need to implement the function to return the values for a given group and channel index. You also need to ensure only the correct subset of values is returned for a given numberToSkip and numberToTake . In addition, you need to implement a callback function to retrieve the channel length. If all channels have the same length, it simply returns a constant. def read_channel_length ( self , grp_index , chn_index ): \"\"\" Returns the channel length as an Integer for a given group and channel index \"\"\" return 10 See full example: csv-read-with-callback-loading","title":"Callback Loading"},{"location":"python-dataplugins/python-dataplugins/#error-handling","text":"Python DataPlugins can raise errors in all callback functions. The raised error is displayed in DIAdem, LabVIEW, or SystemLink DataFinder. def read_store ( self , parameter ): ... raise Exception ( \"Leave read_store with exception\" )","title":"Error Handling"},{"location":"python-dataplugins/python-dataplugins/#not-my-file","text":"A special case is \"Not My File\". This error should be raised when the DataPlugin detects that the file to be opened is not suited for this DataPlugin. This special error can be raised only in the read_store function by returning None : def read_store ( self , parameter ): ... if notMyFile : return None","title":"Not My File"},{"location":"python-dataplugins/python-dataplugins/#export-dataplugin","text":"Export Python DataPlugins to make them available on other systems. Use NI DIAdem to export a DataPlugin as a URI file. Exporting DataPlugins in DIAdem You can also export a DataPlugin from NI's Python DataPlugin Extension for Visual Studio Code: Exporting DataPlugins in VSCode","title":"Export DataPlugin"},{"location":"python-dataplugins/python-dataplugins/#encrypted-dataplugins","text":"In some cases, you may want to protect your code from being viewed by others. Use NI DIAdem to export an encrypted Python DataPlugin. This functionality is not available in the VSCode extension.","title":"Encrypted DataPlugins"},{"location":"python-dataplugins/python-dataplugins/#known-limitations","text":"","title":"Known Limitations"},{"location":"python-dataplugins/python-dataplugins/#numpy-and-pandas","text":"NumPy and Pandas do not run reliably in embedded Python environments and, therefore, NI does not recommend them for use in DataPlugins.","title":"NumPy and Pandas"},{"location":"python-dataplugins/python-dataplugins/#single-file-dataplugins","text":"Python DataPlugins can only be written in a single Python file. Importing sidecar files is not supported. It will fail when exporting the DataPlugin as a URI.","title":"Single File DataPlugins"},{"location":"python-dataplugins/python-dataplugins/#datetimestrptime","text":"There is an open issue in Python for datetime.strptime that prevents the function from working properly in embedded Python environments. Avoid using this function in DataPlugin source code. Instead, add the following function to your code: def strptime ( self , value , format ): return datetime . datetime ( * ( time . strptime ( value , \" %d .%m.%y %H:%M:%S\" )[ 0 : 6 ]))","title":"datetime.strptime"},{"location":"rbac/rbac/","text":"Workspaces and Role-based Access Control \u00b6 The SystemLink role-based access control (RBAC) system provides strong isolation between different workspaces as well as fine grain privileges for systems, data, and analysis routines in SystemLink. Collectively this capability allows access to SystemLink to scale user and data access beyond a single team to an entire organization. Concepts \u00b6 SystemLink RBAC leverages common concepts such as roles and users . It also introduces concepts such as workspaces and automatic data encapsulation to ensure strict access control of data produced by test systems. Role-based access control concepts in SystemLink Workspace \u00b6 A workspace is a complete encapsulation of all systems, data, and other resources within SystemLink. A user must be a member of a workspace to access the systems and data within the workspace. This is true for access via the SystemLink web application and the SystemLink REST API. SystemLink always has at least one workspace, Default , created at install time. Like all workspaces,the default workspace may be renamed or archived , but it has a additional properties to support backwards compatibility with pre-2020R1 SystemLink clients. Properties of the Default workspace All clients using AMQP for network communication exclusively publish data to the default workspace. All pre-2020R1 clients using HTTP for network communication exclusively publish data to the default workspace. OPC UA and Cloud Connector sessions always exist in the default workspace and may only access tags in the default workspace. File moving rules always exist in the default workspace and may only access files in the default workspace. Health tags for the SystemLink server are always published to the default workspace. The SystemLink Advanced Server license is required to create multiple workspaces, but there is no limit on the number of workspaces that can be created. Refer to the SystemLink Manual for steps to create a workspace. Two workspaces with unique resources in each workspace. Resources users can access are determined by their workspace membership. The actions a user can take on each resource are determined by their role. Systems, data, and analysis routines (collectively referred to as resources) are unique to individual workspaces. No resource occupies multiple workspaces. Some resources may be moved between workspaces. If a resource is duplicated the user is prompted to choose a workspace for the new resource. Exceptions for Workspaces \u00b6 The following resources in SystemLink have limitations or exceptions from the broader rules described above. DataFinder : DataFinder instances are global (meaning any user can view the DataFinder instance), but DataFinder Search Areas defined within a DataFinder instance are scoped to a single workspace. Search areas can only index File Ingestion Service data for the DataFinder Search Area's corresponding workspace. All indexed files of a search area are available only to members of the corresponding workspace. Notifications : Notification strategies, groups, and email templates are not scoped to a single workspace. These may be used with any alarm rule regardless of the workspace of the alarm rule. Roles may still restrict access to notification configuration. Jupyter Notebook : Jupyter Notebooks are not managed by SystemLink's RBAC. Refer to Sharing a Jupyter Notebook for details on how to allow multiple users collaborate with Notebooks. Archived Workspaces \u00b6 Workspaces may be archived if they are no longer in use. Archiving does not delete resources or move resources to a new database or file storage location. Archived workspaces are only accessible to users with the Server Administrator role. Resources in archived workspaces cannot be created, updated, or deleted. Resources may be duplicated or moved into a non-archived workspace. All active alarms are automatically cleared when a workspace is archived. Refer to the SystemLink manual for steps to manage archived workspaces. Users and Roles \u00b6 Roles define the privileges a user, system, or analysis procedure may take against resources within SystemLink. While roles are applied within the context of a workspace, roles are defined globally. This enables the same role to be used across multiple workspaces. Refer to the SystemLink manual for steps to manage roles. Role privileges explicitly grant what you can do - there are no deny privileges. Due to this a user may be assigned multiple roles within a single workspace that collectively describe what the user has access to. This is useful to prevent the proliferation of multiple different roles that have similar privileges. Instead, simple roles may be defined and composed together by assigning a user each role. Allow all privileges In each area of available privileges there is an Allow all privileges option. This privilege automatically grants all privileges for that area. If a new privilege is in a future version of SystemLink, users with Allow all privileges will automatically be granted the new privilege upon upgrade. If this behavior is undesirable, refrain from using Allow all privileges . All privileges for an area are granted when Allow all privileges is checked. Built-in and Custom Roles \u00b6 When creating and assigning roles , it is best practice to provide users with the minimum number of privileges to perform their work. SystemLink has granular privileges for services and applications in the product. These privileges also include access to individual SystemLink applications such as Systems Management and Test Insights . Note If a user has a role that grants access to an application in any workspace that application will be available to the user at all times. If a user has not been granted access to an application in any workspace that application will be hidden from the navigation menu. The privilege to access a web application is not sufficient for to view, list, create, modify, or delete resource exposed by the web application. Additional privileges for those resources must be granted. Custom roles may be created, duplicated, modified, and deleted as needed. If a role is updated all users mapped to that role are affected. Due to the large number of privileges available SystemLink includes several built-in roles to facilitate getting started. Refer to the SystemLink manual for a summary of these roles. Go to the SystemLink Access Control application to review the details on privileges granted for each role. Note Built-in roles cannot be modified. They can be duplicated and the duplicated roles may be renamed and the privileges modified. This constraint exists because NI may add or change privileges for built-in roles between releases. Users assigned these built-in roles will have their privileges automatically change upon upgrade. To opt out of this behavior assign your users custom roles. Server Administrator Role \u00b6 SystemLink includes a special Server Administrator Role . This role has exclusive access to the Access Control application and can modify workspaces and roles. This role has full access to all of SystemLink, its applications, data, systems, etc. for every workspace . This is the most permissive role in SystemLink and should be used by users who administer access control for SystemLink exclusively. The user admin created during the guided setup of NI Web Server Configuration is automatically assigned the Server Administrator role. This is done such that administrators can access the Access Control application during initial setup and configure access control via an identity provider. NI encourages disabling the admin user in the NI Web Server Configuration after you have assigned the Server Administrator role to users backed by your identity provider. NI encourages disabling the Login as users controlled by the web server checkbox after mapping Server Administrators from your identity provider. Users are mapped to the Server Administrator role by clicking the gear icon in the top right of the Roles tab in the Access Control application. Click the gear icons to configure mappings for the Server Administrator role. Mappings for users assigned the Server Administrator role Users \u00b6 Users are backed by an identity provider (IdP) such as LDAP, Active Directory, or OpenID Connect that provides authenticated access to SystemLink. This is in contrast to systems and analysis routines that are managed within SystemLink and are not backed by an identity provider. A member of multiple workspaces can view resources across different workspaces in a common grid view. If a user is a member of multiple workspaces, the resources in those workspaces will be shown simultaneously within the grids and other views within SystemLink. This is useful when users need to view a rollup of resources across multiple workspaces. While resources in multiple workspaces may be viewed in a single grid, the actions a user can take against those resources may be different depending on their role in each workspace. Considerations for WebVIs, dashboards, and Jupyter Notebooks The privileges for WebVIs and dashboards control the create, view, update, and delete privileges for the WebVI and dashboard documents themselves. When a user opens and views a dashboard or WebVI the data they can access is determined by the privileges on the resources exposed by the WebVI or dashboard such as tags, queries, and notebooks. If a user does not have privileges to access the resources exposed by the WebVI or dashboard they will view no data. When a user runs a Jupyter Notebook from a Report or dashboard, the Notebook executes with the same privileges as the user. This allows the creation of Notebooks without workspace logic. For example, the Test Insights dashboard includes a tile displaying system utilization over time. This tile will only show utilization for systems within the logged in user's workspaces. If the user does not have privileges to view systems, the tile returns no data. Service roles \u00b6 Service roles apply to SystemLink managed systems and analysis routines executed by Analysis Automation . Systems are always automatically assigned the built-in Automated Agent role. Analysis Automation routines can be configured to run with the built-in Automated Agent role, a user defined service role, with the privileges of the user initiating the analysis task, or with the TDM user (a Windows user on the SystemLink app server defined in NI SystemLink TDM Configuration ). Any custom role may be configured to be a service role at creation by toggling the Service role toggle button in the role configuration slide out. This cannot be changed after role creation. There are no restrictions on the privileges that may be applied to the role. It exists to signal to various SystemLink UIs what roles can be assigned to users and what roles can be assigned to systems and analysis routines. This forces the user to curtail roles appropriately to each scenario and avoid the proliferation of roles that grant greater access than is necessary to a user, system, or analysis routine. A role configured to be a Service role. Automatic Data Encapsulation \u00b6 When a system is added to SystemLink the user must choose in which workspace the system will reside. The workspaces available to the user are determined by both their workspace membership and Add systems privilege. Once added to a workspace, data produced by the system will automatically be stored in the same workspace as the system. This capability allows users to develop workspace agnostic test applications. Changing workspaces does not require changes or redeployment of test application. This is especially helpful when in scenarios such as production verification where the test application cannot change between validation and production but the validation data produced must be kept separate from production data. Systems job history, asset and tag data When a system is added to a workspace all its connected assets are also added to the same workspace. When a system is moved to another workspace its assets and job history are also moved. This is not the case with tags and tag history published by the system. These will be left in the original workspace and new tags are created in the new workspace. Mapping users to roles in workspaces \u00b6 Users are added to a workspace and assigned a role through a process called workspace and role mapping . The process is driven by metadata provided by the identity provider (IdP) user to authenticate users for SystemLink: OpenID Connect , LDAP , Active Directory, or local Windows accounts. Refer to the documentation for each of the IdP types for details on how to configure workspace and role mapping. By using metadata from an IdP you can create mappings that on-board large numbers of users into SystemLink using existing Active Directory and LDAP groups and OpenID Connect claims.","title":"Workspaces and Role-based Access Control"},{"location":"rbac/rbac/#workspaces-and-role-based-access-control","text":"The SystemLink role-based access control (RBAC) system provides strong isolation between different workspaces as well as fine grain privileges for systems, data, and analysis routines in SystemLink. Collectively this capability allows access to SystemLink to scale user and data access beyond a single team to an entire organization.","title":"Workspaces and Role-based Access Control"},{"location":"rbac/rbac/#concepts","text":"SystemLink RBAC leverages common concepts such as roles and users . It also introduces concepts such as workspaces and automatic data encapsulation to ensure strict access control of data produced by test systems. Role-based access control concepts in SystemLink","title":"Concepts"},{"location":"rbac/rbac/#workspace","text":"A workspace is a complete encapsulation of all systems, data, and other resources within SystemLink. A user must be a member of a workspace to access the systems and data within the workspace. This is true for access via the SystemLink web application and the SystemLink REST API. SystemLink always has at least one workspace, Default , created at install time. Like all workspaces,the default workspace may be renamed or archived , but it has a additional properties to support backwards compatibility with pre-2020R1 SystemLink clients. Properties of the Default workspace All clients using AMQP for network communication exclusively publish data to the default workspace. All pre-2020R1 clients using HTTP for network communication exclusively publish data to the default workspace. OPC UA and Cloud Connector sessions always exist in the default workspace and may only access tags in the default workspace. File moving rules always exist in the default workspace and may only access files in the default workspace. Health tags for the SystemLink server are always published to the default workspace. The SystemLink Advanced Server license is required to create multiple workspaces, but there is no limit on the number of workspaces that can be created. Refer to the SystemLink Manual for steps to create a workspace. Two workspaces with unique resources in each workspace. Resources users can access are determined by their workspace membership. The actions a user can take on each resource are determined by their role. Systems, data, and analysis routines (collectively referred to as resources) are unique to individual workspaces. No resource occupies multiple workspaces. Some resources may be moved between workspaces. If a resource is duplicated the user is prompted to choose a workspace for the new resource.","title":"Workspace"},{"location":"rbac/rbac/#exceptions-for-workspaces","text":"The following resources in SystemLink have limitations or exceptions from the broader rules described above. DataFinder : DataFinder instances are global (meaning any user can view the DataFinder instance), but DataFinder Search Areas defined within a DataFinder instance are scoped to a single workspace. Search areas can only index File Ingestion Service data for the DataFinder Search Area's corresponding workspace. All indexed files of a search area are available only to members of the corresponding workspace. Notifications : Notification strategies, groups, and email templates are not scoped to a single workspace. These may be used with any alarm rule regardless of the workspace of the alarm rule. Roles may still restrict access to notification configuration. Jupyter Notebook : Jupyter Notebooks are not managed by SystemLink's RBAC. Refer to Sharing a Jupyter Notebook for details on how to allow multiple users collaborate with Notebooks.","title":"Exceptions for Workspaces"},{"location":"rbac/rbac/#archived-workspaces","text":"Workspaces may be archived if they are no longer in use. Archiving does not delete resources or move resources to a new database or file storage location. Archived workspaces are only accessible to users with the Server Administrator role. Resources in archived workspaces cannot be created, updated, or deleted. Resources may be duplicated or moved into a non-archived workspace. All active alarms are automatically cleared when a workspace is archived. Refer to the SystemLink manual for steps to manage archived workspaces.","title":"Archived Workspaces"},{"location":"rbac/rbac/#users-and-roles","text":"Roles define the privileges a user, system, or analysis procedure may take against resources within SystemLink. While roles are applied within the context of a workspace, roles are defined globally. This enables the same role to be used across multiple workspaces. Refer to the SystemLink manual for steps to manage roles. Role privileges explicitly grant what you can do - there are no deny privileges. Due to this a user may be assigned multiple roles within a single workspace that collectively describe what the user has access to. This is useful to prevent the proliferation of multiple different roles that have similar privileges. Instead, simple roles may be defined and composed together by assigning a user each role. Allow all privileges In each area of available privileges there is an Allow all privileges option. This privilege automatically grants all privileges for that area. If a new privilege is in a future version of SystemLink, users with Allow all privileges will automatically be granted the new privilege upon upgrade. If this behavior is undesirable, refrain from using Allow all privileges . All privileges for an area are granted when Allow all privileges is checked.","title":"Users and Roles"},{"location":"rbac/rbac/#built-in-and-custom-roles","text":"When creating and assigning roles , it is best practice to provide users with the minimum number of privileges to perform their work. SystemLink has granular privileges for services and applications in the product. These privileges also include access to individual SystemLink applications such as Systems Management and Test Insights . Note If a user has a role that grants access to an application in any workspace that application will be available to the user at all times. If a user has not been granted access to an application in any workspace that application will be hidden from the navigation menu. The privilege to access a web application is not sufficient for to view, list, create, modify, or delete resource exposed by the web application. Additional privileges for those resources must be granted. Custom roles may be created, duplicated, modified, and deleted as needed. If a role is updated all users mapped to that role are affected. Due to the large number of privileges available SystemLink includes several built-in roles to facilitate getting started. Refer to the SystemLink manual for a summary of these roles. Go to the SystemLink Access Control application to review the details on privileges granted for each role. Note Built-in roles cannot be modified. They can be duplicated and the duplicated roles may be renamed and the privileges modified. This constraint exists because NI may add or change privileges for built-in roles between releases. Users assigned these built-in roles will have their privileges automatically change upon upgrade. To opt out of this behavior assign your users custom roles.","title":"Built-in and Custom Roles"},{"location":"rbac/rbac/#server-administrator-role","text":"SystemLink includes a special Server Administrator Role . This role has exclusive access to the Access Control application and can modify workspaces and roles. This role has full access to all of SystemLink, its applications, data, systems, etc. for every workspace . This is the most permissive role in SystemLink and should be used by users who administer access control for SystemLink exclusively. The user admin created during the guided setup of NI Web Server Configuration is automatically assigned the Server Administrator role. This is done such that administrators can access the Access Control application during initial setup and configure access control via an identity provider. NI encourages disabling the admin user in the NI Web Server Configuration after you have assigned the Server Administrator role to users backed by your identity provider. NI encourages disabling the Login as users controlled by the web server checkbox after mapping Server Administrators from your identity provider. Users are mapped to the Server Administrator role by clicking the gear icon in the top right of the Roles tab in the Access Control application. Click the gear icons to configure mappings for the Server Administrator role. Mappings for users assigned the Server Administrator role","title":"Server Administrator Role"},{"location":"rbac/rbac/#users","text":"Users are backed by an identity provider (IdP) such as LDAP, Active Directory, or OpenID Connect that provides authenticated access to SystemLink. This is in contrast to systems and analysis routines that are managed within SystemLink and are not backed by an identity provider. A member of multiple workspaces can view resources across different workspaces in a common grid view. If a user is a member of multiple workspaces, the resources in those workspaces will be shown simultaneously within the grids and other views within SystemLink. This is useful when users need to view a rollup of resources across multiple workspaces. While resources in multiple workspaces may be viewed in a single grid, the actions a user can take against those resources may be different depending on their role in each workspace. Considerations for WebVIs, dashboards, and Jupyter Notebooks The privileges for WebVIs and dashboards control the create, view, update, and delete privileges for the WebVI and dashboard documents themselves. When a user opens and views a dashboard or WebVI the data they can access is determined by the privileges on the resources exposed by the WebVI or dashboard such as tags, queries, and notebooks. If a user does not have privileges to access the resources exposed by the WebVI or dashboard they will view no data. When a user runs a Jupyter Notebook from a Report or dashboard, the Notebook executes with the same privileges as the user. This allows the creation of Notebooks without workspace logic. For example, the Test Insights dashboard includes a tile displaying system utilization over time. This tile will only show utilization for systems within the logged in user's workspaces. If the user does not have privileges to view systems, the tile returns no data.","title":"Users"},{"location":"rbac/rbac/#service-roles","text":"Service roles apply to SystemLink managed systems and analysis routines executed by Analysis Automation . Systems are always automatically assigned the built-in Automated Agent role. Analysis Automation routines can be configured to run with the built-in Automated Agent role, a user defined service role, with the privileges of the user initiating the analysis task, or with the TDM user (a Windows user on the SystemLink app server defined in NI SystemLink TDM Configuration ). Any custom role may be configured to be a service role at creation by toggling the Service role toggle button in the role configuration slide out. This cannot be changed after role creation. There are no restrictions on the privileges that may be applied to the role. It exists to signal to various SystemLink UIs what roles can be assigned to users and what roles can be assigned to systems and analysis routines. This forces the user to curtail roles appropriately to each scenario and avoid the proliferation of roles that grant greater access than is necessary to a user, system, or analysis routine. A role configured to be a Service role.","title":"Service roles"},{"location":"rbac/rbac/#automatic-data-encapsulation","text":"When a system is added to SystemLink the user must choose in which workspace the system will reside. The workspaces available to the user are determined by both their workspace membership and Add systems privilege. Once added to a workspace, data produced by the system will automatically be stored in the same workspace as the system. This capability allows users to develop workspace agnostic test applications. Changing workspaces does not require changes or redeployment of test application. This is especially helpful when in scenarios such as production verification where the test application cannot change between validation and production but the validation data produced must be kept separate from production data. Systems job history, asset and tag data When a system is added to a workspace all its connected assets are also added to the same workspace. When a system is moved to another workspace its assets and job history are also moved. This is not the case with tags and tag history published by the system. These will be left in the original workspace and new tags are created in the new workspace.","title":"Automatic Data Encapsulation"},{"location":"rbac/rbac/#mapping-users-to-roles-in-workspaces","text":"Users are added to a workspace and assigned a role through a process called workspace and role mapping . The process is driven by metadata provided by the identity provider (IdP) user to authenticate users for SystemLink: OpenID Connect , LDAP , Active Directory, or local Windows accounts. Refer to the documentation for each of the IdP types for details on how to configure workspace and role mapping. By using metadata from an IdP you can create mappings that on-board large numbers of users into SystemLink using existing Active Directory and LDAP groups and OpenID Connect claims.","title":"Mapping users to roles in workspaces"},{"location":"upgrade/upgrade/","text":"Upgrading and Migrating SystemLink Server \u00b6 This chapter covers how to maintain a fully operable SystemLink Server while upgrading to a new version of SystemLink or migrating between SystemLink servers. To simplify creating and restoring backups, NI recommends running SystemLink Server, attached file stores, and databases within virtual machines. Backing up physical machines is outside the scope of this chapter. Assumptions and Prerequisites \u00b6 A server running SystemLink 2021 R1 or greater. Migrating from older versions of SystemLink is not supported at this time. Familiarity with installing and setting up a SystemLink Server Setting up a SystemLink Server Configuring NI Web Server Sign on with LDAP Single Sign-on with OpenID Connect Data Store Configuration MongoDB Connecting to a Remote Mongo Database Connecting to a Remote File Share Uploading Files to Amazon Simple Storage Service (S3) Connecting to a Remote PostgreSQL Database Recommended Virtual machines to run all servers, file stores, a databases Removable storage volume or device Preparing for Upgrade or Migration \u00b6 Before you begin, backup your server and any remote data to avoid unplanned downtime if issues occur during the upgrade or migration process. Single Node versus Multi Node Configurations Single node refers to the SystemLink Server configuration where the application server, file storage, and databases used by SystemLink are all installed on the same Windows server. This is the default configuration for SystemLink Server. Multi node refers to configurations where one or more file stores or databases used by SystemLink are running on hardware distinct from the SystemLink application server. This is the recommended configuration for all production deployments. NI-SystemLink-Migration Command Line Utility \u00b6 The workflows for upgrades and migrations makes use of the SystemLink command line migration tool, nislmigrate . Refer to the NI-SystemLink-Migration documentation in PyPi for details on installing and using this tool. Limitations of nislmigrate The NI-SystemLin-Migration tool does not yet support migrating all data in SystemLink. Refer to the Supported Services table on PyPi for details. Argument Flags for nislmigrate nislmigrate supports capturing data from individual services or can capture data from all installed services using the --all argument flag. For brevity --all is used most workflows in this chapter. Depending on your needs you may replace the --all argument flag with one or more of the individual service argument flags. Upgrading from SystemLink 21.3 or earlier to SystemLink 21.5 or later \u00b6 After upgrading from SystemLink 21.3 or earlier to SystemLink 21.5 or later, SystemLink will migrate your test steps, results, and products from MongoDB to PostgreSQL. Depending on the size of your data set this process may take some time. For reference, a typical server takes less than one hour to migrate 5 million steps. To check the step count on your server, you can use the Mongo shell or a client such as Robo 3T. The credentials required for connecting to the database can be found in C:\\ProgramData\\National Instruments\\Skyline\\Config\\TestMonitor.json . Use the step count to roughly estimate the expected migration time. Note that system resources and network connectivity will impact the migration time. If Test Monitor is using the local instance of MongoDB stored in the default location, the migration will occur automatically. If not, the migration must be approved on the TestMonitor tab in the NI SystemLink Server Configuration application. The TestMonitor service will display a status of Migrating during this process. You can view detailed status of this process with C:\\ProgramData\\National Instruments\\Skyline\\Logs\\log.txt . If you see an error, double check your connection string and restart SystemLink Service Manager. Recommended Upgrade and Migration Workflows for your deployment \u00b6 While you should plan for some downtime of your SystemLink Server, you can minimize that downtime by following these recommendations. Single Node Upgrade Single Node to Multi Node Migration Single Node to Multi Node with MongoDB Single Node to Multi Node with File Storage Single Node to Multi Node with PostgreSQL Upgrading Multi node configurations (MongoDB, PostgreSQL, File Share/S3) Seamless cut-over If you have a SystemLink Server with a small amount of data, you can use nislmigrate to backup your data to the local file system of your SystemLink Server. For SystemLink Servers with a large amount of data, you may need to use an attached volume since the backup created by nislmigrate may exhaust the local storage. This document assumes that you are using an attached volume and refers to the volume as D:\\ in each workflow. Storing Sensitive Data The migration of systems data ( --all or --systems ) will migrate the private key used decrypt communication between your SystemLink server and test systems. In this case, nislmigrate requires the use of the --secret argument to encrypt this key. While this provides some assurances of the security of this private key, it is the users responsibility to ensure this private key and sensitive production data are properly handled during migration and after the process is complete. Single Node Upgrade \u00b6 Complete the following steps to upgrade a single node deployment of SystemLink Server. Though the NI Package Manager (NIPM) installer for SystemLink supports in-place upgrades where the upgrade runs directly on your current SystemLink Server, NI does not recommend this option. If you choose this option, ensure that you backup your server before beginning the upgrade. For single node upgrades, NI recommends upgrading and migrating at the same time to mitigate issues during the upgrade by ensuring your original SystemLink Server remains operable. Backup your SystemLink Server. Attach a volume to store data captured by nislmigrate . This will be referenced as D:\\ . Install nislmigrate . Run the command nislmigrate capture --all --secret <your secret> --dir D:\\migration . Note While nislmigrate runs all SystemLink services are stopped. Plan ahead for this downtime of your SystemLink server. When the capture is completed, SystemLink services will be restarted automatically. Detach D:\\ . Note After this step, your original SystemLink Server is still operable, but any new data created or consumed by SystemLink Server at this time will not be available to your new server. Provision a new Windows server for SystemLink. Install and configure the new version of SystemLink Server. Install nislmigrate on your new SystemLink Server. Attach the D:\\ volume used to capture data from your original SystemLink Server. Run the command nislmigrate restore --all --secret <your secret> --dir D:\\migration . Verify your new SystemLink Server has all the expected migrated data. Single Node to Multi Node Migration \u00b6 This section describes workflows to prepare to upgrade or migrate from a single node SystemLink Server configuration to a multi node SystemLink Server configuration that makes use of dedicated servers for MongoDB, PostgreSQL, or file storage. Single Node to Multi Node with MongoDB \u00b6 Complete the following steps to upgrade a single node deployment of SystemLink Server to a multi node deployment where the MongoDB instance used by SystemLink is hosted on its own server or replica set. Backup your SystemLink Server. Attach a volume to store data captured by nislmigrate . This will be referenced as D:\\ . Install nislmigrate . Run the command nislmigrate capture --all --secret <your secret> --dir D:\\migration . Detach D:\\ . Note After this step, your original SystemLink Server is still operable, but any new data created or consumed by SystemLink Server at this time will not be available to your new server. Provision a new Windows server for SystemLink. Note While not required, provisioning a new SystemLink Server ensures your original SystemLink Server is always in an operable state. Provision a new MongoDB server or replica set . Install and configure the same or a newer version of SystemLink Server. Configure SystemLink to use the newly created MongoDB server or replica set. Install nislmigrate on your new SystemLink Server. Attach the D:\\ volume used to capture data from your original SystemLink server. Run the command nislmigrate restore --all --secret <your secret> --dir D:\\migration . Verify your new SystemLink Server has all the expected migrated data. Single Node to Multi Node with File Storage \u00b6 Complete the following steps to upgrade a single node deployment of SystemLink Server to a multi node deployment where the file storage instance used by SystemLink is hosted on sa dedicated NAS, SAN, or AWS S3. Backup your SystemLink Server. Attach a volume to store data captured by nislmigrate . This will be referenced as D:\\ . Install nislmigrate . Run the command nislmigrate capture --all --secret <your secret> --dir D:\\migration . Copy the files from the original file storage location to the new file store using one of the following options. Destination Recommended Tool NAS File Explorer or PowerShell SAN File Explorer or PowerShell AWS S3 AWS CLI Detach D:\\ . Note After this step, your original SystemLink Server is still operable, but any new data created or consumed by SystemLink Server at this time will not be available to your new server. Provision a new file store for SystemLink. Install and configure the same or a newer version of SystemLink Server. Configure SystemLink to use the newly created file storage location. Install nislmigrate on your new SystemLink Server. Attach the D:\\ volume used to capture data from your original SystemLink server. Run the command nislmigrate restore --all --secret <your secret> --change-file-store-root <new root> --dir D:\\migration . Note You must use the --change-file-store-root argument flag to update the file meta data the new root location of your file storage. Otherwise, you will not be able to preview or download files. Depending on your configuration, this could be a new drive letter, UNC path, or S3 URL. Migration Destination Example nislmigrate Command New drive and directory nislmigrate restore --all --secret <your secret> --change-file-store-root X:\\systemlink\\data --dir D:\\migration UNC path nislmigrate restore --all --secret <your secret> --change-file-store-root \\\\FileShare\\systemlink\\data --dir D:\\migration AWS S3 nislmigrate restore --all --secret <your secret> --change-file-store-root s3://yours3bucket/systemlink/data/ --dir D:\\migration Verify your new SystemLink Server has all the expected migrated data. Single Node to Multi Node with PostgreSQL \u00b6 Complete the following steps to upgrade a single node deployment of SystemLink Server to a multi node deployment where the PostgreSQL instance used by the SystemLink Test Monitor service is hosted on its own server or replica set. The Test Monitor Service performs the migration of test steps, test results, and product from MongoDB to PostgreSQL. As of SystemLink 21.5, SystemLink supports using a local or external PostgreSQL database for the Test Monitor service. nislmigrate does not yet support migrating between PostgreSQL servers or replica sets. Backup your SystemLink Server. Attach a volume to store data captured by nislmigrate . This will be referenced as D:\\ . Install nislmigrate . Run the command nislmigrate capture --all --secret <your secret> --dir D:\\migration . Detach D:\\ . Note After this step, your original SystemLink Server is still operable, but any new data created or consumed by SystemLink Server at this time will not be available to your new server. Provision a new Windows server for SystemLink. Provision a PostgreSQL server or replica set. Install and configure SystemLink 21.5 or later. Install nislmigrate on your new SystemLink Server. Attach the D:\\ volume used to capture data from your original SystemLink server. Run the command nislmigrate restore --all --secret <your secret> --dir D:\\migration . Open the NI SystemLink Server Configuration application. Navigate to PostgreSQLDatabase and connect to your external PostgreSQL database. See the SystemLink manual for more details. Navigate to TestMonitor, approve the migration, and click Apply to begin the migration. Verify your new SystemLink Server has all the expected migrated data. Upgrading Multi Node Configurations \u00b6 Complete the following steps to upgrade a SystemLink Server instance that has been configured to use a dedicated MongoDB server or replica set, a dedicated PostgreSQL server or replica set, and a dedicated file store such as AWS S3. Note NI recommends using dedicated external data stores for all production deployments. The following workflow assumes you are in this configuration when upgrading SystemLink Server. Refer to the other workflows in this document to migrate your data into this configuration. Backup your SystemLink Server, MongoDB server or replica set, PostgreSQL server or replica set, and file store. Note If S3 is used as your file store the backup step is not needed since this managed internally by AWS. Attach a volume to store data captured by nislmigrate . This will be referenced as D:\\ . Install nislmigrate . Run the command nislmigrate capture --tags --dir D:\\migration . Note While most of the data is external to SystemLink, tag current values are stored on the app server. Therefore this nislmigrate argument flag must be used to ensure that data is not lost during the migration. Be aware this operation will also replace tag history data stored in MongoDB. Detach D:\\ . Note After this step your original SystemLink Server is in an operable state. Be aware if any new data is created or ingested by the SystemLink server at this time it will not be available to your new server. Provision a new Windows server for SystemLink. Provision a MongoDB server or replica set from the backup previously created. Provision a PostgreSQL server or replica set from the backup previously created. Note The previous steps prescribe using a newly created instance of your MongoDB or PostgreSQL servers. This is because SystemLink may change the internal schema of these databases when services start post upgrade. If you do not start with an instance from a backup you will be unable to revert the MongoDB collections and PostgreSQL tables into the schemas needed for the older version of SystemLink. Install and configure the new version of SystemLink Server. Configure SystemLink to use the newly created MongoDB server or replica set, PostgreSQL server or replica set, and existing file store. Install nislmigrate on your new SystemLink Server. Attach the D:\\ volume used to capture data from your original SystemLink server. Run the command nislmigrate restore --tags --dir D:\\migration . Verify your new SystemLink Server has all the expected migrated data. Seamless Cut-over \u00b6 Since managed test systems are connected SystemLink test systems can connect to the new instance of SystemLink without manual intervention. To accomplish this the following conditions must be met: Migration of systems data. This is either accomplished by using the nislmigrate argument flags --all or --systems . These migration arguments must be used even in cases where an external MongoDB server or replica set is used. Otherwise the systems management private key is not retained and test systems will need to be approved again to connect to your SystemLink server. The DNS name of the original SystemLink Server and the new SystemLink Server are the same. If NI Web Server has been configured for HTTPS, the new SystemLink Server must use the same TLs certificate as the original SystemLink Server.","title":"Upgrading and Migrating SystemLink Server"},{"location":"upgrade/upgrade/#upgrading-and-migrating-systemlink-server","text":"This chapter covers how to maintain a fully operable SystemLink Server while upgrading to a new version of SystemLink or migrating between SystemLink servers. To simplify creating and restoring backups, NI recommends running SystemLink Server, attached file stores, and databases within virtual machines. Backing up physical machines is outside the scope of this chapter.","title":"Upgrading and Migrating SystemLink Server"},{"location":"upgrade/upgrade/#assumptions-and-prerequisites","text":"A server running SystemLink 2021 R1 or greater. Migrating from older versions of SystemLink is not supported at this time. Familiarity with installing and setting up a SystemLink Server Setting up a SystemLink Server Configuring NI Web Server Sign on with LDAP Single Sign-on with OpenID Connect Data Store Configuration MongoDB Connecting to a Remote Mongo Database Connecting to a Remote File Share Uploading Files to Amazon Simple Storage Service (S3) Connecting to a Remote PostgreSQL Database Recommended Virtual machines to run all servers, file stores, a databases Removable storage volume or device","title":"Assumptions and Prerequisites"},{"location":"upgrade/upgrade/#preparing-for-upgrade-or-migration","text":"Before you begin, backup your server and any remote data to avoid unplanned downtime if issues occur during the upgrade or migration process. Single Node versus Multi Node Configurations Single node refers to the SystemLink Server configuration where the application server, file storage, and databases used by SystemLink are all installed on the same Windows server. This is the default configuration for SystemLink Server. Multi node refers to configurations where one or more file stores or databases used by SystemLink are running on hardware distinct from the SystemLink application server. This is the recommended configuration for all production deployments.","title":"Preparing for Upgrade or Migration"},{"location":"upgrade/upgrade/#ni-systemlink-migration-command-line-utility","text":"The workflows for upgrades and migrations makes use of the SystemLink command line migration tool, nislmigrate . Refer to the NI-SystemLink-Migration documentation in PyPi for details on installing and using this tool. Limitations of nislmigrate The NI-SystemLin-Migration tool does not yet support migrating all data in SystemLink. Refer to the Supported Services table on PyPi for details. Argument Flags for nislmigrate nislmigrate supports capturing data from individual services or can capture data from all installed services using the --all argument flag. For brevity --all is used most workflows in this chapter. Depending on your needs you may replace the --all argument flag with one or more of the individual service argument flags.","title":"NI-SystemLink-Migration Command Line Utility"},{"location":"upgrade/upgrade/#upgrading-from-systemlink-213-or-earlier-to-systemlink-215-or-later","text":"After upgrading from SystemLink 21.3 or earlier to SystemLink 21.5 or later, SystemLink will migrate your test steps, results, and products from MongoDB to PostgreSQL. Depending on the size of your data set this process may take some time. For reference, a typical server takes less than one hour to migrate 5 million steps. To check the step count on your server, you can use the Mongo shell or a client such as Robo 3T. The credentials required for connecting to the database can be found in C:\\ProgramData\\National Instruments\\Skyline\\Config\\TestMonitor.json . Use the step count to roughly estimate the expected migration time. Note that system resources and network connectivity will impact the migration time. If Test Monitor is using the local instance of MongoDB stored in the default location, the migration will occur automatically. If not, the migration must be approved on the TestMonitor tab in the NI SystemLink Server Configuration application. The TestMonitor service will display a status of Migrating during this process. You can view detailed status of this process with C:\\ProgramData\\National Instruments\\Skyline\\Logs\\log.txt . If you see an error, double check your connection string and restart SystemLink Service Manager.","title":"Upgrading from SystemLink 21.3 or earlier to SystemLink 21.5 or later"},{"location":"upgrade/upgrade/#recommended-upgrade-and-migration-workflows-for-your-deployment","text":"While you should plan for some downtime of your SystemLink Server, you can minimize that downtime by following these recommendations. Single Node Upgrade Single Node to Multi Node Migration Single Node to Multi Node with MongoDB Single Node to Multi Node with File Storage Single Node to Multi Node with PostgreSQL Upgrading Multi node configurations (MongoDB, PostgreSQL, File Share/S3) Seamless cut-over If you have a SystemLink Server with a small amount of data, you can use nislmigrate to backup your data to the local file system of your SystemLink Server. For SystemLink Servers with a large amount of data, you may need to use an attached volume since the backup created by nislmigrate may exhaust the local storage. This document assumes that you are using an attached volume and refers to the volume as D:\\ in each workflow. Storing Sensitive Data The migration of systems data ( --all or --systems ) will migrate the private key used decrypt communication between your SystemLink server and test systems. In this case, nislmigrate requires the use of the --secret argument to encrypt this key. While this provides some assurances of the security of this private key, it is the users responsibility to ensure this private key and sensitive production data are properly handled during migration and after the process is complete.","title":"Recommended Upgrade and Migration Workflows for your deployment"},{"location":"upgrade/upgrade/#single-node-upgrade","text":"Complete the following steps to upgrade a single node deployment of SystemLink Server. Though the NI Package Manager (NIPM) installer for SystemLink supports in-place upgrades where the upgrade runs directly on your current SystemLink Server, NI does not recommend this option. If you choose this option, ensure that you backup your server before beginning the upgrade. For single node upgrades, NI recommends upgrading and migrating at the same time to mitigate issues during the upgrade by ensuring your original SystemLink Server remains operable. Backup your SystemLink Server. Attach a volume to store data captured by nislmigrate . This will be referenced as D:\\ . Install nislmigrate . Run the command nislmigrate capture --all --secret <your secret> --dir D:\\migration . Note While nislmigrate runs all SystemLink services are stopped. Plan ahead for this downtime of your SystemLink server. When the capture is completed, SystemLink services will be restarted automatically. Detach D:\\ . Note After this step, your original SystemLink Server is still operable, but any new data created or consumed by SystemLink Server at this time will not be available to your new server. Provision a new Windows server for SystemLink. Install and configure the new version of SystemLink Server. Install nislmigrate on your new SystemLink Server. Attach the D:\\ volume used to capture data from your original SystemLink Server. Run the command nislmigrate restore --all --secret <your secret> --dir D:\\migration . Verify your new SystemLink Server has all the expected migrated data.","title":"Single Node Upgrade"},{"location":"upgrade/upgrade/#single-node-to-multi-node-migration","text":"This section describes workflows to prepare to upgrade or migrate from a single node SystemLink Server configuration to a multi node SystemLink Server configuration that makes use of dedicated servers for MongoDB, PostgreSQL, or file storage.","title":"Single Node to Multi Node Migration"},{"location":"upgrade/upgrade/#single-node-to-multi-node-with-mongodb","text":"Complete the following steps to upgrade a single node deployment of SystemLink Server to a multi node deployment where the MongoDB instance used by SystemLink is hosted on its own server or replica set. Backup your SystemLink Server. Attach a volume to store data captured by nislmigrate . This will be referenced as D:\\ . Install nislmigrate . Run the command nislmigrate capture --all --secret <your secret> --dir D:\\migration . Detach D:\\ . Note After this step, your original SystemLink Server is still operable, but any new data created or consumed by SystemLink Server at this time will not be available to your new server. Provision a new Windows server for SystemLink. Note While not required, provisioning a new SystemLink Server ensures your original SystemLink Server is always in an operable state. Provision a new MongoDB server or replica set . Install and configure the same or a newer version of SystemLink Server. Configure SystemLink to use the newly created MongoDB server or replica set. Install nislmigrate on your new SystemLink Server. Attach the D:\\ volume used to capture data from your original SystemLink server. Run the command nislmigrate restore --all --secret <your secret> --dir D:\\migration . Verify your new SystemLink Server has all the expected migrated data.","title":"Single Node to Multi Node with MongoDB"},{"location":"upgrade/upgrade/#single-node-to-multi-node-with-file-storage","text":"Complete the following steps to upgrade a single node deployment of SystemLink Server to a multi node deployment where the file storage instance used by SystemLink is hosted on sa dedicated NAS, SAN, or AWS S3. Backup your SystemLink Server. Attach a volume to store data captured by nislmigrate . This will be referenced as D:\\ . Install nislmigrate . Run the command nislmigrate capture --all --secret <your secret> --dir D:\\migration . Copy the files from the original file storage location to the new file store using one of the following options. Destination Recommended Tool NAS File Explorer or PowerShell SAN File Explorer or PowerShell AWS S3 AWS CLI Detach D:\\ . Note After this step, your original SystemLink Server is still operable, but any new data created or consumed by SystemLink Server at this time will not be available to your new server. Provision a new file store for SystemLink. Install and configure the same or a newer version of SystemLink Server. Configure SystemLink to use the newly created file storage location. Install nislmigrate on your new SystemLink Server. Attach the D:\\ volume used to capture data from your original SystemLink server. Run the command nislmigrate restore --all --secret <your secret> --change-file-store-root <new root> --dir D:\\migration . Note You must use the --change-file-store-root argument flag to update the file meta data the new root location of your file storage. Otherwise, you will not be able to preview or download files. Depending on your configuration, this could be a new drive letter, UNC path, or S3 URL. Migration Destination Example nislmigrate Command New drive and directory nislmigrate restore --all --secret <your secret> --change-file-store-root X:\\systemlink\\data --dir D:\\migration UNC path nislmigrate restore --all --secret <your secret> --change-file-store-root \\\\FileShare\\systemlink\\data --dir D:\\migration AWS S3 nislmigrate restore --all --secret <your secret> --change-file-store-root s3://yours3bucket/systemlink/data/ --dir D:\\migration Verify your new SystemLink Server has all the expected migrated data.","title":"Single Node to Multi Node with File Storage"},{"location":"upgrade/upgrade/#single-node-to-multi-node-with-postgresql","text":"Complete the following steps to upgrade a single node deployment of SystemLink Server to a multi node deployment where the PostgreSQL instance used by the SystemLink Test Monitor service is hosted on its own server or replica set. The Test Monitor Service performs the migration of test steps, test results, and product from MongoDB to PostgreSQL. As of SystemLink 21.5, SystemLink supports using a local or external PostgreSQL database for the Test Monitor service. nislmigrate does not yet support migrating between PostgreSQL servers or replica sets. Backup your SystemLink Server. Attach a volume to store data captured by nislmigrate . This will be referenced as D:\\ . Install nislmigrate . Run the command nislmigrate capture --all --secret <your secret> --dir D:\\migration . Detach D:\\ . Note After this step, your original SystemLink Server is still operable, but any new data created or consumed by SystemLink Server at this time will not be available to your new server. Provision a new Windows server for SystemLink. Provision a PostgreSQL server or replica set. Install and configure SystemLink 21.5 or later. Install nislmigrate on your new SystemLink Server. Attach the D:\\ volume used to capture data from your original SystemLink server. Run the command nislmigrate restore --all --secret <your secret> --dir D:\\migration . Open the NI SystemLink Server Configuration application. Navigate to PostgreSQLDatabase and connect to your external PostgreSQL database. See the SystemLink manual for more details. Navigate to TestMonitor, approve the migration, and click Apply to begin the migration. Verify your new SystemLink Server has all the expected migrated data.","title":"Single Node to Multi Node with PostgreSQL"},{"location":"upgrade/upgrade/#upgrading-multi-node-configurations","text":"Complete the following steps to upgrade a SystemLink Server instance that has been configured to use a dedicated MongoDB server or replica set, a dedicated PostgreSQL server or replica set, and a dedicated file store such as AWS S3. Note NI recommends using dedicated external data stores for all production deployments. The following workflow assumes you are in this configuration when upgrading SystemLink Server. Refer to the other workflows in this document to migrate your data into this configuration. Backup your SystemLink Server, MongoDB server or replica set, PostgreSQL server or replica set, and file store. Note If S3 is used as your file store the backup step is not needed since this managed internally by AWS. Attach a volume to store data captured by nislmigrate . This will be referenced as D:\\ . Install nislmigrate . Run the command nislmigrate capture --tags --dir D:\\migration . Note While most of the data is external to SystemLink, tag current values are stored on the app server. Therefore this nislmigrate argument flag must be used to ensure that data is not lost during the migration. Be aware this operation will also replace tag history data stored in MongoDB. Detach D:\\ . Note After this step your original SystemLink Server is in an operable state. Be aware if any new data is created or ingested by the SystemLink server at this time it will not be available to your new server. Provision a new Windows server for SystemLink. Provision a MongoDB server or replica set from the backup previously created. Provision a PostgreSQL server or replica set from the backup previously created. Note The previous steps prescribe using a newly created instance of your MongoDB or PostgreSQL servers. This is because SystemLink may change the internal schema of these databases when services start post upgrade. If you do not start with an instance from a backup you will be unable to revert the MongoDB collections and PostgreSQL tables into the schemas needed for the older version of SystemLink. Install and configure the new version of SystemLink Server. Configure SystemLink to use the newly created MongoDB server or replica set, PostgreSQL server or replica set, and existing file store. Install nislmigrate on your new SystemLink Server. Attach the D:\\ volume used to capture data from your original SystemLink server. Run the command nislmigrate restore --tags --dir D:\\migration . Verify your new SystemLink Server has all the expected migrated data.","title":"Upgrading Multi Node Configurations"},{"location":"upgrade/upgrade/#seamless-cut-over","text":"Since managed test systems are connected SystemLink test systems can connect to the new instance of SystemLink without manual intervention. To accomplish this the following conditions must be met: Migration of systems data. This is either accomplished by using the nislmigrate argument flags --all or --systems . These migration arguments must be used even in cases where an external MongoDB server or replica set is used. Otherwise the systems management private key is not retained and test systems will need to be approved again to connect to your SystemLink server. The DNS name of the original SystemLink Server and the new SystemLink Server are the same. If NI Web Server has been configured for HTTPS, the new SystemLink Server must use the same TLs certificate as the original SystemLink Server.","title":"Seamless Cut-over"}]}